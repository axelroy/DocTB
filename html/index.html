
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="fr">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Bienvenue sur la documentation du travail de Bachelor Auto ML &#8212; documentation AutoML 0.0.1</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/translations.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Recherche" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="bienvenue-sur-la-documentation-du-travail-de-bachelor-auto-ml">
<h1>Bienvenue sur la documentation du travail de Bachelor Auto ML<a class="headerlink" href="#bienvenue-sur-la-documentation-du-travail-de-bachelor-auto-ml" title="Lien permanent vers ce titre">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Lien permanent vers ce titre">¶</a></h1>
<p>Le présent document fait office de rapport de projet.
Il permet de comprendre le contexte de celui-ci, de décrire les éléments qui le compose,
fait une analyse de la problématique, la conception en vue de la résolution et
présente l’implémentation effectuée. Ce document ne présente pas tout le cheminement,
mais uniquement l’état final</p>
<div class="section" id="contexte-du-projet">
<h2>Contexte du projet<a class="headerlink" href="#contexte-du-projet" title="Lien permanent vers ce titre">¶</a></h2>
<p>Le présent projet s’inscrit dans le cadre du travail de Bachelor en Informatique option «&nbsp;Développement logiciel
et multimédia&nbsp;», réalisé à la HE-ARC de Neuchâtel.</p>
<p>Le projet est effectué pour le CHUV-LREN dans le cadre du «&nbsp;Human Brain Project&nbsp;».</p>
<div class="section" id="human-brain-projet">
<h3>Human Brain projet<a class="headerlink" href="#human-brain-projet" title="Lien permanent vers ce titre">¶</a></h3>
<p>Ce projet s’inscrit dans le cadre du projet Européen «&nbsp;Human Brain Project&nbsp;».
Ce chapitre vise à expliquer le contexte du sous-projet 8, et ce qui nous intéresse.</p>
</div>
<div class="section" id="presentation-de-la-plateforme-mip">
<h3>Présentation de la plateforme MIP<a class="headerlink" href="#presentation-de-la-plateforme-mip" title="Lien permanent vers ce titre">¶</a></h3>
<p>Le but du sous-projet 8 du HBP est de fournir une plateforme pour effectuer des
expériences neuroscientifiques sur des données de patients recueillies à travers les
cliniques et hôpitaux partenaires. Etant donné la nature médicale de ces données,
elles sont bien évidemment anonymisées, et il n’est pas possible de retrouver les
données d’un patient, car les données sont présentées sous la forme d’agrégation
par caractéristique, comme le présente la <a href="#features">figure  300</a></p>
<div class="figure align-center" id="id55">
<span id="features"></span><a class="reference internal image-reference" href="_images/Agregation_features_MIP.png"><img alt="Représentation des caractéristiques d'intérêts" src="_images/Agregation_features_MIP.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text"><em>Représentation des caractéristiques d’intérêts.</em></span></p>
</div>
<p>En sélectionnant un des ronds blancs, on accède à la variable en question,
et on peut observer différentes statistiques, comme par exemple des vues sous forme d’histogrammes [cf <a href="#histogram">figure  301</a>]</p>
<div class="figure align-center" id="id56">
<span id="histogram"></span><a class="reference internal image-reference" href="_images/Histogram_features_MIP.png"><img alt="Exemple d'histogramme d'une variable." src="_images/Histogram_features_MIP.png" style="width: 450px;" /></a>
<p class="caption"><span class="caption-text"><em>Exemple d’histogramme d’une variable.</em></span></p>
</div>
<p>Il est ainsi possible d’accéder à toutes les caractéristiques médicales et ainsi
de les analyser manuellement. La plateforme permet aussi de formuler des expériences
basées sur les données, afin de proposer un modèle permettant d’essayer
de trouver des liens entre les variables des patients et leur diagnostiques médicaux.
La plateforme vise à formuler des expériences liées à Alzheimer,
mais d’autres maladie neurologiques pourraient être visées. A partir d’une caractéristique,
l’utilisateur peut décider de formuler une expérience en choisissant dans laquelle
des catégories suivantes il compte l’impliquer&nbsp;:</p>
<ul class="simple">
<li>Variable, qui correspondent à la cible de l’expérience;</li>
<li>Co-variable, qui correspondent aux variables de l’expériences.</li>
<li>Filtre</li>
</ul>
<p>Via l’interface suivante présentée en <a href="#variables">figure  302</a>.</p>
<div class="figure align-center" id="id57">
<span id="variables"></span><a class="reference internal image-reference" href="_images/Variables_experiences.png"><img alt="Exemple de formulation d'expérience, étape selection des variables. Cet exemple vise à trouver un lien entre la quantité de matière grise dans le Cuneus en fonction de l'age et du sexe." src="_images/Variables_experiences.png" style="width: 450px;" /></a>
<p class="caption"><span class="caption-text"><em>Exemple de formulation d’expérience, étape selection des variables. Cet exemple vise à trouver un lien entre la quantité de matière grise dans le Cuneus gauche en fonction de l’age et du sexe.</em></span></p>
</div>
<p>Ce qui permet d’analyser des graphes mêlant les différentes
variables. Il est encore possible de paramétrer la représentation sur l’axe via
une boite à outils, afin de faire ressortir les informations intéressantes, comme le montre la <a href="#resultnoml">figure  303</a></p>
<div class="figure align-center" id="id58">
<span id="resultnoml"></span><a class="reference internal image-reference" href="_images/Resultat_nonML_experiment.png"><img alt="Résultat de l'expérience formulée à la :num:`figure #variables`. Représentation de la quantité de matière grise en cm3 en fonction de l'age et du sexe (bordeau = femme, rose = homme)." src="_images/Resultat_nonML_experiment.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text"><em>Résultat de l’expérience formulée Représentation de la quantité de matière grise en cm3 en fonction de l’age et du sexe (bordeau = femme, rose = homme).</em></span></p>
</div>
<p>La partie intéressante dans le cadre de ce projet est la possibilité, à partir des
variables sélectionnées, de lancer une expérience d’apprentissage automatique
(<em>Machine Learning</em>) afin de trouver le modèle qui permet de représenter au mieux
le lien entre les caractéristiques et le diagnostique.</p>
<p>L’aide pour la configuration de l’expérience est présentée comme en <a href="#helpconfig">figure  304</a></p>
<div class="figure align-center" id="id59">
<span id="helpconfig"></span><a class="reference internal image-reference" href="_images/description_experience.png"><img alt="Aide pour la formulation d'une expérience de Machine Learning." src="_images/description_experience.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text"><em>Aide pour la formulation d’une expérience de Machine Learning.</em></span></p>
</div>
<p>Les étapes 1 et 2 sont celles qui nous intéressent&nbsp;:</p>
<p>L’étape 1 correspond à la sélection d’un algorithme de <em>Machine Learning</em> dans
la liste fournie (catégories&nbsp;: analyse statistique, extraction de caractéristiques
et modèle prédictif). Le modèle choisi influence fortement les résultats de l’expérience.</p>
<p>Lorsque le modèle est sélectionné, il est nécessaire, suivant le modèle, de devoir
renseigner des «&nbsp;<strong>paramètres</strong>&nbsp;» pour celui-ci. Nous appellerons ces paramètres
des «&nbsp;<strong>hyper-paramètres</strong>&nbsp;», afin d’éviter la confusion avec les paramètres
qui sont les coefficients internes qui ont été déterminés après l’entraînement.
Les hyper-paramètres définissent l’architecture ou le fonctionnement de l’algorithme (par exemple, pour le
modèle KNN, l’hyper-paramètre k désigne le nombre des voisins les plus proches
sur lesquels on veut travailler). Le choix de ces hyper-paramètres est donné au
points 2 de cette marche à suivre. Pour un même modèle, le choix d’un
hyper-paramètres plutôt qu’un autre change à nouveau drastiquement les résultats.</p>
<p>L’utilisateur peut définir plusieurs configurations «&nbsp;modèle-paramètres&nbsp;» pour une expérience.
Une expérience ne donne pas instantanément ses résultats. L’utilisateur est notifié
lorsque les résultats sont consultables.</p>
<p>C’est ici que s’inscrit le projet. L’utilisateur, qui est probablement plus un spécialiste
en neuroscience qu’en informatique, se trouve obligé de paramétrer et choisir des données
qui sont liées uniquement à l’informatique.</p>
</div>
<div class="section" id="but-du-projet">
<h3>But du projet<a class="headerlink" href="#but-du-projet" title="Lien permanent vers ce titre">¶</a></h3>
<p>Ce projet a pour but de mettre en place un moyen pour que l’utilisateur n’ait plus
à s’occuper du choix du modèle et du paramétrage pour son expérience, et que la
plateforme s’occupe de trouver automatiquement la meilleure configuration possible.
Dans l’idéal, l’utilisateur n’a qu’un bouton à presser pour cette étape.</p>
</div>
</div>
</div>
<div class="section" id="cahier-des-charges-lien-vers-les-annexes-je-suppose-en-sachant-qu-il-est-explique-en-detail-dans-le-document">
<h1>Cahier des charges (lien vers les annexes je suppose, en sachant qu’il est expliqué en détail dans le document)<a class="headerlink" href="#cahier-des-charges-lien-vers-les-annexes-je-suppose-en-sachant-qu-il-est-explique-en-detail-dans-le-document" title="Lien permanent vers ce titre">¶</a></h1>
<p>Se référer au cahier des charges fourni en annexes.</p>
</div>
<div class="section" id="etat-de-l-art">
<h1>Etat de l’Art<a class="headerlink" href="#etat-de-l-art" title="Lien permanent vers ce titre">¶</a></h1>
<p>Avant de se lancerdans la description du travail,
il est intéressant d’effectuer un état de l’art des technologies qui pourraient
nous intéresser. Etant donné que le projet consiste à ajouter des fonctionnalités
à un projet existant, cette section décrira les technologies actuellement existantes,
ainsi que les technologies ajoutées, ou tout du moins leur champ d’application.</p>
<p>Cette section est rédigée en listant les différentes technologies, de la plus globale
à la plus précise en terme d’utilisation dans le projet.</p>
<div class="section" id="theorie-machine-learning">
<h2>Théorie Machine Learning<a class="headerlink" href="#theorie-machine-learning" title="Lien permanent vers ce titre">¶</a></h2>
<p>Le <em>Machine Learning</em> (apprentissage automatique en francais), est un champ d’activité
de l’intelligence artificielle qui vise à permettre à une machine d’apprendre par elle-même
plutôt que d’en fixer tous les comportements de manière programmatique.
Elle est particulièrement utilisée dans les problématiques où le nombre de cas
est trop important pour être codés à la mano. Le panel d’utilisation est large,
il peut par exemple concerner&nbsp;:</p>
<ul class="simple">
<li>L’analyse de graphes ou de données</li>
<li>La classification d’individus</li>
<li>La résolution de problèmes de régression</li>
<li>La reconnaissance d’objets</li>
<li>L’analyse de documents (notamment pour les moteurs de recherche)</li>
<li>La reconnaissance de caractères manuscrits</li>
<li>L’aide au diagnostiques médicaux</li>
</ul>
<p>Dans notre cas, l’apprentissage automatique est implémenté dans la plateforme via les méthodes suivantes&nbsp;:</p>
<ul class="simple">
<li>Résumé statistique ;</li>
<li>Analyse de la variance (anova) ;</li>
<li>Régression linéaire ;</li>
<li>KNN</li>
<li>Classification naïve bayésienne</li>
</ul>
<p>Mais on peut aussi ajouter à la plateforme d’autres méthodes d’apprentissage automatique
via des containers <em>Docker</em> préconfigurés qui sont fournis par le projet.</p>
<div class="section" id="apprentissage-supervise">
<h3>Apprentissage supervisé<a class="headerlink" href="#apprentissage-supervise" title="Lien permanent vers ce titre">¶</a></h3>
<p>Dans cette méthodologie, on connait déjà les classes que l’on souhaite pouvoir déterminer
automatiquement via l’algorithme. Ces classes sont tirées des données par un expert.
Dans certains cas, il est aussi possible d’attribuer une probabilité d’appartenance à une classe.
L’apprentissage se déroule généralement en deux phases. La première phase est dite d’entrainement.
Elle consiste à déterminer un modèle qui permet de reproduire pour de nouvelles données la même
classification/régression que celle donnée via les labels. La seconde phase est dite de validation.
Elle consiste à déterminer si le modèle entrainé est pertinent, via des méthodes métriques.
Ces deux phases ne s’effectuent pas sur les mêmes données. La phase d’entrainement nécessite
une quantité d’informations suffisantes afin d’avoir un modèle représentatif.</p>
</div>
<div class="section" id="apprentissage-non-supervise">
<h3>Apprentissage non supervisé<a class="headerlink" href="#apprentissage-non-supervise" title="Lien permanent vers ce titre">¶</a></h3>
<p>Cet apprentissage s’applique à des données qui ne sont pas labellées par des classes.
C’est ici à la machine de déterminer les différentes classes qui représentent le problème.
A partir d’un ensemble de données en entrées, il va chercher à créer des classes représentatives
pour celles-ci, en maximisant la distance inter-classe, et en minimisant la distance des éléments intra-classe
comme représenté sur la <a href="#distanceml">figure  305</a>.</p>
<div class="figure align-center" id="id60">
<span id="distanceml"></span><a class="reference internal image-reference" href="_images/distance_illustration.png"><img alt="Représentation des distances inter-classe et intra-classe. Illustration issue du site Microsoft :cite:`&#64;theoryMLMS`" src="_images/distance_illustration.png" style="width: 300px;" /></a>
<p class="caption"><span class="caption-text">Représentation des distances inter-classe et intra-classe. Illustration issue du site MSDN <a class="reference internal" href="#theorymlms" id="id1">[8]</a></span></p>
</div>
<p>Cette méthodologie peut aussi permettre d’analyser la relation entre les variables, par
exemple pour réduire la dimension des vecteurs d’entrées.</p>
</div>
<div class="section" id="apprentissage-semi-supervise">
<h3>Apprentissage semi-supervisé<a class="headerlink" href="#apprentissage-semi-supervise" title="Lien permanent vers ce titre">¶</a></h3>
<p>Etant donné que l’apprentissage supervisé nécessite un labelisation des données par expert,
il devient très coûteux de réaliser ce travail au fur et à mesure que les données augmentent.
L’utilisation de données labellées, liées à des données labellées, peut permettre d’améliorer
la qualité de l’apprentissage. Par exemple, il est ainsi possible d’utiliser un classificateur
crée par l’apprentissage supervisé, et un autre crée par l’apprentissage non-supervisé.</p>
<p>Idéalement, les deux classificateurs ne se basent pas sur les mêmes caractéristiques, ce qui
permet de recouper les deux classificateurs afin d’affiner la classification finale.</p>
</div>
</div>
<div class="section" id="optimisation-automatique-du-pipeline-d-apprentissage">
<h2>Optimisation automatique du pipeline d’apprentissage<a class="headerlink" href="#optimisation-automatique-du-pipeline-d-apprentissage" title="Lien permanent vers ce titre">¶</a></h2>
<p>De manière générale, le <em>Machine Learning</em> est décrit comme une suite d’opérations à
effectuer de manière séquentielle pour permettre de résoudre une problématique. On parle dès
lors de pipeline, étant donné que chaque étape est effectuée, à la manière d’un flux
d’opérations, de la première à la dernière.</p>
<p>Ce pipeline est généralement découpé en deux phases distinctes :</p>
<ul class="simple">
<li>Extraction, normalisation et éventuellement construction des caractéristiques à partir des données brutes.</li>
<li>Application d’un modèle statistique ou linéaire pour effectuer, selon la problématique, une classification ou une régression.</li>
</ul>
<p>On peut représenter ce flux via la <a href="#mlpipeline">figure  306</a>:</p>
<div class="figure align-center" id="id61">
<span id="mlpipeline"></span><a class="reference internal image-reference" href="_images/ml_pipeline.png"><img alt="Exemple d'un pipeline de *Machine Learning*, tiré de la documentation TPOT :cite:`Olson2016EvoBio` et modifié pour supprimer les parties liées à TPOT." src="_images/ml_pipeline.png" style="width: 650px;" /></a>
<p class="caption"><span class="caption-text">Exemple d’un pipeline de Machine Learning, tiré de la documentation TPOT <a class="reference internal" href="#olson2016evobio" id="id2">[23]</a> et adapté pour supprimer les parties liées à TPOT.</span></p>
</div>
<p>On peut en décrire les phases ainsi :</p>
<ul class="simple">
<li><strong>Data Cleaning</strong>&nbsp;: Mise en forme des données et nettoyage. Ceci peut consister à renseigner les données manquantes.</li>
<li><strong>Features Preprocessing</strong>&nbsp;: Transformation des caractéristiques pour les rendre plus utilisables dans le contexte, par exemple en les normalisant.</li>
<li><strong>Features Selection</strong>&nbsp;: Sélection des caractéristiques les plus pertinentes pour le modèle.</li>
<li><strong>Feature Construction</strong>&nbsp;: Création de nouvelles caractéristiques à partir des données.</li>
<li><strong>Model Selection</strong>&nbsp;: Sélection du type de modèle ainsi que les hyper-paramètres liés à celui-ci (p.e. pour un réseau de neurones, le nombre de couches de neurones). Actuellement, l’utilisateur doit les configurer lui-même, et même un utilisateur expert ne peut pas garantir que ce sont les meilleurs hyper-paramètres possibles.</li>
<li><strong>Parameter Optimization</strong>&nbsp;: le choix d’un modèle détermine les paramètres qui lui sont liés (p.e. pour un réseau de neurones, le poids de chaque neurone). Ces paramètres  influencent énormément la performance du modèle. Ils sont définis lors de cette phase.</li>
<li><strong>Model Validation</strong>&nbsp;: En sortie, nous avons, pour un ensemble de caractéristiques donnée, un modèle et le hyper-paramètres de ce modèle. Il faut ensuite valider ce modèle sur un ensemble de sujets différents afin de déterminer sa pertinence.</li>
</ul>
<p>Dans une approche traditionnelle d’optimisation d’une expérience de <em>Machine Learning</em>,
on essaie de faire varier les hyper-paramètres du modèle (p.e via les grid-search <a class="reference internal" href="#datagridsearchdoc" id="id3">[5]</a> de Scikit-Learn <a class="reference internal" href="#scikit-learn" id="id4">[26]</a>).</p>
<p>Cette méthode permet d’optimiser les hyper-paramètres du modèle. Ce dernier doit avoir
été sélectionné manuellement auparavant par l’utilisateur. De plus, l’étendue et le pas des hyper-paramètres sont
eux-aussi déterminés manuellement, ce qui réduit le domaine d’exploration.</p>
<p>Une tendance émergente de ces dernières années est d’utiliser des méthodes d’intelligence artificielle pour
explorer l’espace des solutions de manière automatique et optimisée. Cette exploration est souvent effectuée
via des algorithmes génétiques car ils
correspondent à la problématique d’exploration d’un espace de solutions de grande dimension.
Cette exploration est effectuée de manière non dirigée tout en fournissant un résultat exploitable.</p>
<p>Les réelles avancées dans le domaine sont récentes, les premiers articles concrets datent de
2016, et il est difficile de trouver des exemples dans un domaine concret, prouvant l’efficacité de <em>l’Automated Machine Learning</em> .
Les créateurs de bibliothèque TPOT <a class="reference internal" href="#olson2016evobio" id="id5">[23]</a> ont rédigé deux papiers <a class="reference internal" href="#olson2016evaluation" id="id6">[21]</a> <a class="reference internal" href="#olson2016tpot" id="id7">[22]</a>
d’exemple d’applications dans des cas réels, sur la classification de cas de cancers de la prostate, en comprarant
l’approche conventionnelle et  l’approche <em>Automed Machine Learning</em>, et ont pu mettre en avant
une amélioration des résultats.
Google a récemment communiqué son intérêt pour le domaine, en annoncant l’ouverture d’un département
sur la recherche de cette discipline <a class="reference internal" href="#googleautoml" id="id8">[4]</a>. Certains sites spécialisés <a class="reference internal" href="#stateautoml" id="id9">[20]</a> <a class="reference internal" href="#hhusain" id="id10">[12]</a>
décrivent ce domaine avec intérêt, mais en précisant que les résultats ne sont pas encore
probants, et que, pour le moment, elle n’est pas applicable à toutes les problématiques.</p>
<p>Dans le cadre du projet, étant donné que les utilisateurs ne sont pas experts dans
le domaine du <em>Machine Learning</em>, il est probable que les résultats soient meilleurs que
les configurations des utilisateurs.</p>
<p>Si le travail abouti à une expérience, il est possible que celui-ci soit publié.</p>
</div>
<div class="section" id="technologies">
<h2>Technologies<a class="headerlink" href="#technologies" title="Lien permanent vers ce titre">¶</a></h2>
<div class="section" id="tpot">
<h3>TPOT<a class="headerlink" href="#tpot" title="Lien permanent vers ce titre">¶</a></h3>
<p><em>TPOT</em> <a class="reference internal" href="#olson2016evobio" id="id11">[23]</a> est une bibliothèque <em>open-source</em> permettant l’optimisation
de pipeline automatisée, alias <em>automated Machine Learning</em>. Elle se distingue des autres
bibliothèques telles que Auto-WEKA <a class="reference internal" href="#autoweka" id="id12">[2]</a> et Hyperopt <a class="reference internal" href="#hyperopt" id="id13">[13]</a> par le fait
qu’il est capable non seulement de faire varier les modèles et le hyper-paramètres,
mais qu’elle est aussi capable de sélectionner, construire ou d’effectuer du préprocessing
sur les caractéristiques. <em>TPOT</em> dispose d’une communauté active, et le créateur,*Randy Olson*,
répond très rapidement aux <em>issues</em> postées sur le <em>Github</em> de <em>TPOT</em>.</p>
<p>La <a href="#mlpipelinetpot">figure  307</a> présente un flux de <em>Machine Learning</em>.</p>
<div class="figure align-center" id="id62">
<span id="mlpipelinetpot"></span><a class="reference internal image-reference" href="_images/tpot-ml-pipeline.png"><img alt="Exemple d'un pipeline de Machine Learning, avec les parties gérées automatiquement par TPOT. Illustration tirée de la documentation TPOT :cite:`Olson2016EvoBio`" src="_images/tpot-ml-pipeline.png" style="width: 650px;" /></a>
<p class="caption"><span class="caption-text">Exemple d’un pipeline de Machine Learning, avec les parties gérées automatiquement par TPOT. Illustration tirée de la documentation TPOT <a class="reference internal" href="#olson2016evobio" id="id14">[23]</a></span></p>
</div>
<p>Les différentes étapes ont la même signification que présenté au point de <a class="reference internal" href="#mlphases"><span class="std std-ref">présentation des phases typiques de machine learning</span></a>,
au dessous de la <a href="#mlpipeline">figure  306</a>.</p>
<p>Cette bibliothèque est codée en Python, et se base sur les modèles de Scikit-learn <a class="reference internal" href="#scikit-learn" id="id15">[26]</a>, ce qui
permet d’avoir une compatibilité avec cette bibliothèque <em>Python</em>.</p>
</div>
<div class="section" id="systemes-distribues">
<h3>Systèmes distribués<a class="headerlink" href="#systemes-distribues" title="Lien permanent vers ce titre">¶</a></h3>
<p>Historiquement, avant que le web ne vienne changer la donne, une application était
localisé sur une machine unique, et son architecture se présentait comme sur la <a href="#computerarchi">figure  308</a></p>
<div class="figure align-center" id="id63">
<span id="computerarchi"></span><a class="reference internal image-reference" href="_images/computer_architecture.png"><img alt="Architecture simple basée sur une machine unique" src="_images/computer_architecture.png" style="width: 200px;" /></a>
<p class="caption"><span class="caption-text">Architecture simple basée sur une application unique : crédits &#64; Groovytron <a class="reference internal" href="#groovytron" id="id16">[9]</a></span></p>
</div>
<p>Avec l’augmentation de la demande, la première approche pour augmenter la capacité
de réponse a été de parraléliser plusieurs machines sur le réseau, et d’effectuer
un balancage de charge entre les différentes instances, en fonction des moyens.</p>
<p>Les machines sont déployées en cluster (groupes de machines), et le <em>load-balancer</em>
s’occupe de répartir les requêtes, comme présenté à la <a href="#highavailability">figure  309</a>.</p>
<div class="figure align-center" id="id64">
<span id="highavailability"></span><a class="reference internal image-reference" href="_images/high_availability_architecture.png"><img alt="Architecture orientée haute disponibilité et «scalabilité»" src="_images/high_availability_architecture.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text"><em>Architecture orientée haute disponibilité et «scalabilité» : crédits &#64; Groovytron</em></span></p>
</div>
<p>Avec la venue d’internet, l’utilisation des applications a changée, et elles ont
été amenées à communiquer entre elles, afin de partager des données ou des services.</p>
<p>Dès lors, le découpage des applications s’est effectué par bloc, chaque application
étant indépendante, mais fourni une interface comme point d’entrée pour communiquer,
et s’appuie généralement sur un format d’encodage haut-niveau (XML, JSON, …).
pour formuler des réponses aux autres applications. On a ainsi un découpage plus fin
des fonctionnalités, mais ce découpage engendre un travail supplémentaire pour le
programmeur.</p>
<p>Etant donné que les machines sont indépendantes, la gestion des ressources s’effectue
pour chacune en local. Dans l’approche d’un système distribué, on cherche à pouvoir
gérer le plus finement les ressources au niveau du cluster, et pas uniquement par
un balanceur de charge.</p>
<p>Un système d’exploitation distribué tel que <em>DC/OS</em> est un système
qui se superpose au système d’exploitation de la machine, et qui fournit une gestion
fine des ressources. La <a href="#distributedos">figure  310</a> permet d’illustrer cette architecture.</p>
<div class="figure align-center" id="id65">
<span id="distributedos"></span><a class="reference internal image-reference" href="_images/container_orchestration_revised.png"><img alt="Architecture utilisant un outils d'orchestration de containers" src="_images/container_orchestration_revised.png" style="width: 550px;" /></a>
<p class="caption"><span class="caption-text"><em>Architecture superposant un système d’exploitation distribué au système d’exploitation natif de la machine.: crédits &#64; Groovytron</em></span></p>
</div>
<p><em>DC/OS</em> est issu de la <em>Mesosphere</em>, un ensemble d’outils fournis par Apache qui
répondent spécifiquement aux problématiques du cloud-computing. L’architecture du CHUV
est basée sur les outils de la <em>Mesosphere</em>, mais n’utilise pas <em>DC/OS</em> au complet.</p>
<p>Ces outils utilisés dans le cadre du projet sont décrits dans la suite du document.</p>
</div>
<div class="section" id="mesos">
<h3>Mesos<a class="headerlink" href="#mesos" title="Lien permanent vers ce titre">¶</a></h3>
<p>Elément central de l’architecture distribuée utilisée au CHUV, <em>Mesos</em> <a class="reference internal" href="#mesosdoc" id="id17">[6]</a> est un noyau
exécuté sur chaque machine du cluster, qui fournit une abstraction des ressources
des machines du cluster. Il est ainsi possible de lancer une application en définissant
la quantité de mémoire vive, le nombre de processeurs, et l’espace disque à disposition,
et Mesos s’occupe de gérer les ressources et la localisation de celles-ci, mais aussi
de gérer le redémarrage de services en cas de pannes, et la mise à l’échelle d’un
service.</p>
<p>Il permet de lancer des applications natives, mais aussi des containers <em>Docker</em>,
comme c’est le cas dans ce projet.</p>
<p>Le cluster est organisé sous la forme d’un noeud <em>Master</em>, et de noeuds <em>Slaves</em>.
Le noeud <em>Master</em> est responsable de recevoir les demandes d’instanciations de services,
et il envoie les ordres au noeud <em>Slave</em> approprié, selon les ressources disponibles.
La communication entre le <em>Master</em> et les <em>Slaves</em> est effectué via <em>ZooKeeper</em>, qui
est un système de stockage clé-valeurs dans un système de fichiers, ce qui permet
de partager les configurations des différents acteurs de l’architecture.</p>
<p>Mesos sert de support pour l’instanciation de services sur notre architecture distribuée.</p>
</div>
<div class="section" id="marathon">
<h3>Marathon<a class="headerlink" href="#marathon" title="Lien permanent vers ce titre">¶</a></h3>
<p><em>Marathon</em> est un logiciel développé par <em>Apache</em> dans le cadre de la <em>Mesosphere</em>.
La Mesosphère est l’ensemble des outils qui sont utilisés dans le cadre de <em>DC/OS</em>, et qui
sont officiellement soutenus par la fondation <em>Apache</em>. <em>Marathon</em> joue le rôle de surcouche
à Mesos afin de simplifier le déploiement de <strong>services longues durées</strong>, c’est à
dire qu’une définition de tâche adressée à <em>Marathon</em> concerne un certain nombre
d’instances de ce service, et que si une instance vient à se stopper,
<em>Marathon</em> va automatiquement relancer une instance de ce service.</p>
<p>Le logiciel fournit une <em>API REST</em> <a class="reference internal" href="#marathonapidoc" id="id18">[7]</a> pour instancier des services
via d’autres applications.</p>
</div>
<div class="section" id="chronos">
<h3>Chronos<a class="headerlink" href="#chronos" title="Lien permanent vers ce titre">¶</a></h3>
<p><em>Chronos</em> est un logiciel développé par la <em>communauté</em> Mesos. Cette communauté,
contrairement à la <em>Mesosphere</em>, n’est pas officiellement soutenue par <em>Apache</em>,
mais est constituée de gens ayant des interêts à développer des outils liés à la Mesosphère,
et qui collaborent en suivant le développement des outils de la <em>Mesosphère</em>.
La pérénité de ces outils ne sont donc pas garantis.</p>
<p><em>Chronos</em> fait office de remplacement à <em>cron</em> de <em>Linux</em>, qui est un service permettant
de planifier des commandes à effectuer à intervalles réguliers. Chronos permet d’effectuer
le même travail sur un système distribué via <em>Mesos</em>.</p>
<p>Il s’oppose à <em>Marathon</em> dans son utilisation, car il permet de lancer une commande
ou un container de manière spontanée, ou programmée, mais qu’il ne cherchera pas à
garder en tout temps un certain nombre d’instances en cours d’exécution.</p>
<p>Il fournit une interface graphique [cf <a href="#chronosgui">figure  311</a>] permettant de programmer une nouvelle tâche planifiée,
mais aussi une <em>API REST</em> permettant l’automatisation programmatique de création de tâches.</p>
<div class="figure align-center" id="id66">
<span id="chronosgui"></span><a class="reference internal image-reference" href="_images/chronos_gui.png"><img alt="Capture d'écran de l'interface graphique de Chronos" src="_images/chronos_gui.png" style="width: 650px;" /></a>
<p class="caption"><span class="caption-text"><em>Capture d’écran de l’interface graphique de Chronos</em></span></p>
</div>
</div>
<div class="section" id="docker">
<h3>Docker<a class="headerlink" href="#docker" title="Lien permanent vers ce titre">¶</a></h3>
<p><em>Docker</em> est une solution <em>open-source</em> qui permet d’embarquer une application
dans un container <em>Linux</em> qui peut être executé sur n’importe quelle machine supportant
le moteur <em>Docker</em>.</p>
<p>Dans une deuxième mesure, il fournit des mécanismes pour rendre un container proche
de la virtualisation, en permettant d’isoler les containers entre eux, mais tout en
fonctionnant sur le même système hôte. Ceci a l’avantage par rapport à la virtualisation
de ne pas embarquer le système d’exploitation pour chaque container virtuel, ce qui
réduit la taille des images. En revanche, étant donné que le système d’exploitation
est partagé, et malgré les mécanismes d’isolation entre container et hôte, il est très
difficile d’arriver à un niveau de sécurité identique à celui des machines virtuelles,
qui elles peuvent être sécurisées jusqu’aux niveau des instructions micro-processeurs.</p>
<p>Docker s’utilise généralement pour uniformiser les conditions de développement, car on
peut dire qu’une image fonctionnant en <em>stand-alone</em> (c’est à dire sans interactions
avec le système hôte, comme par exemple un montage de volume) doit fonctionner sur une autre machine
supportant le moteur <em>Docker</em>.</p>
<p>D’un point de vue haut niveau, un container est par défaut isolé de l’hôte au niveau :</p>
<ul class="simple">
<li>du réseau ;</li>
<li>du système de fichier ;</li>
<li>des paquets installés ;</li>
<li>des services ;</li>
<li>des utilisateurs.</li>
<li>des processus (en partie);</li>
</ul>
<p>Ce qui n’implique pas qu’il est impossible d’accéder à ces différentes instances
de l’hôte, plus ou moins sciemment.</p>
<p>Docker se base sur un système d’image et d’héritage. Il est possible de créer son image
personnalisée à partir d’une image minimale fournie par la communauté comme :</p>
<ul class="simple">
<li>BusyBox;</li>
<li>CentOS / Scientific Linux CERN (SLC) on Debian/Ubuntu or on CentOS/RHEL/SLC/etc;</li>
<li>Debian / Ubuntu;</li>
</ul>
<p>Mais aussi from <code class="code docutils literal"><span class="pre">scratch</span></code>, ou via une archive <a class="reference internal" href="#createbaseimagedocker" id="id19">[14]</a>.</p>
<p>De plus, on peut hériter de n’importe quelle image et la redéfinir via sa propre surcouche.
Les images dont on hérite ne sont pas modifiables. L’héritage est possible pour toute image
publiée sur un dépot d’image Docker (généralement Docker Hub, mais on peut en utiliser d’autres).</p>
<p>La spécialisation du comportement d’un container Docker s’effectue via un fichier de
définition, le <cite>Dockerfile</cite>. Ce fichier est constitué de commandes <a class="reference internal" href="#dockerfilereference" id="id20">[15]</a>
qui peuvent effectuer des actions pour construire l’image, dont les principales sont :</p>
<ul class="simple">
<li>Définir de quelle image on hérite;</li>
<li>Copier un fichier de l’hôte à l’intérieur du système de fichier interne;</li>
<li>Exécuter une commande bash;</li>
<li>Définir des variables d’environnements;</li>
<li>Définir quels ports on veut exposer à l’hôte.</li>
</ul>
<p>Si on souhaite pouvoir choisir entre plusieurs commandes, on peut définir des <code class="code docutils literal"><span class="pre">entrypoints</span></code>,
qui définissent un script que l’on peut exécuter suivant les paramètres d’appels
du container.</p>
<p>Il y a deux méthodes d’intéraction avec un container :</p>
<ul class="simple">
<li><code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span></code></li>
<li><code class="code docutils literal"><span class="pre">docker</span> <span class="pre">exec</span></code></li>
</ul>
<p>La méthode <cite>run</cite> instancie le container. Il permet de définir des paramètres qui définiront
des caractéristiques internes ou externes du container. Il est par exemple possible de
définir le nom du container, un argument d’entrée (utilisable par l’entrypoint) ou
des variables d’environnement. Suivant l’implémentation du container, il est possible
que celui-ci agisse comme un service, et se maintienne en vie, en attente de nouveaux
événements, ou qu’il se termine dès que le travail interne soit terminé. Dans les deux cas,
il se contente d’attendre que le travail interne(souvent implémenté par un script) renvoie
un code d’exécution. <a class="reference internal" href="#codeerrorissue" id="id21">[35]</a></p>
<p>La méthode exec ne peut s’appeler que sur un container qui a déjà été instancié.
Si le container est en cours d’exécution, il est possible d’envoyer une nouvelle commande
au container. La plus classique est l’exécution d’un bash en mode interactif, via la commande
code:<cite>docker exec -it containername bash</cite> qui permet d’exécuter une ligne de commande bash.
Le paramètre <cite>-it</cite> permet justement de laisser la commande en mode intéractif, ce qui
permet de ne pas fermer l’exécution de la commande dès que celle-ci renvoie un code <cite>0</cite>.</p>
<p>Il est possible de formuler une description d’architecture composée de containers
<em>Docker</em> sous la forme d’un fichier <cite>docker-compose.yml</cite>, qui peut se présenter ainsi :</p>
<div class="highlight-yaml"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">version</span><span class="p p-Indicator">:</span> <span class="s">&#39;2&#39;</span>

<span class="l l-Scalar l-Scalar-Plain">services</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">zoo1</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">image</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">zookeeper:3.4</span>
    <span class="l l-Scalar l-Scalar-Plain">ports</span><span class="p p-Indicator">:</span>
       <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">2181:2181</span>

  <span class="l l-Scalar l-Scalar-Plain">mesos-master</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">image</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">mesosphere/mesos-master:1.3.0</span>
    <span class="l l-Scalar l-Scalar-Plain">environment</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_CLUSTER=local</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_ZK=zk://zoo1:2181/mesos</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_QUORUM=1</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_CLUSTER=docker-compose</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_WORK_DIR=/var/lib/mesos</span>

  <span class="l l-Scalar l-Scalar-Plain">mesos-slave</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">image</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">mesosphere/mesos-slave:1.3.0</span>
    <span class="l l-Scalar l-Scalar-Plain">privileged</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
    <span class="l l-Scalar l-Scalar-Plain">environment</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_PORT=5051</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_MASTER=zk://zoo1:2181/mesos</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_CONTAINERIZERS=docker,mesos</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_WORK_DIR=/var/lib/mesos</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">MESOS_SWITCH_USER=0</span>
    <span class="l l-Scalar l-Scalar-Plain">volumes</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/sys/fs/cgroup:/sys/fs/cgroup</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/usr/bin/docker:/usr/bin/docker.so</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">/var/run/docker.sock:/var/run/docker.sock</span>

  <span class="l l-Scalar l-Scalar-Plain">chronos</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">image</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">mesosphere/chronos:v3.0.2</span>
    <span class="l l-Scalar l-Scalar-Plain">ports</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">4400:4400</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">8081:8081</span>
    <span class="l l-Scalar l-Scalar-Plain">environment</span><span class="p p-Indicator">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">PORT0=4400</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">PORT1=8081</span>
    <span class="l l-Scalar l-Scalar-Plain">command</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">--zk_hosts zoo1:2181 --master zk://zoo1:2181/mesos</span>
</pre></div>
</div>
<p>On peut ici voir les configurations de variables d’environnement, de volumes, d’exposition
de ports du container à l’hôte, les versions d’images ainsi que les commandes à
exécuter lorsque le container est prêt.</p>
<p>L’infrastructure peut être lancée via la commande <code class="code docutils literal"><span class="pre">docker-compose</span> <span class="pre">up</span></code>. Le fichier
présenté ici ne propose pas de dépendances pour le lancement, ce qui implique que tous
les containers vont tenter de se monter en même temps. Bien qu’une directive <code class="code docutils literal"><span class="pre">depends-on</span></code>
existe pour <em>docker-compose</em>, cette option est récente, et ne fonctionne pas à tous les coups.
On préférera utiliser un script <em>bash</em> qui s’occupe de démarrer les composants prioritaires
un à un via la commande <code class="code docutils literal"><span class="pre">docker-compose</span> <span class="pre">up</span> <span class="pre">nomducomposant</span></code>.</p>
<p>Il est intéressant de soulever que <em>docker-compose</em> s’occupe seul d’éviter les conflits
de noms de container, contrairement à un démarrage via <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span></code>.</p>
</div>
<div class="section" id="scala">
<h3>Scala<a class="headerlink" href="#scala" title="Lien permanent vers ce titre">¶</a></h3>
<p>Ce travail est effectué au cœur du projet Woken du Human Brain Project. Ce projet
contient le langage de programmation Scala <a class="reference internal" href="#id53" id="id22">[18]</a>. Scala a été concu à l’école polytechnique
de Lausanne (EPFL) afin de proposer de lier des paradigmes de programmation différents
et habituellement opposés, tels que la programmation fonctionnelle et la programmation
orientée objet. Scala se base sur la <em>JVM</em>, ce qui permet de bénéficier de l’abstraction
de celle-ci en termes de plateforme d’exécution, ainsi que pour la gestion de la mémoire.
Scala coopère ainsi de manière transparente avec Java, ce qui permet d’utiliser
des bibliothèques non codées en Scala.</p>
</div>
<div class="section" id="akka">
<h3>AKKA<a class="headerlink" href="#akka" title="Lien permanent vers ce titre">¶</a></h3>
<p>Akka <a class="reference internal" href="#id54" id="id23">[19]</a> est un outil de développement et un environnement d’exécution libre et
open-source qui a pour but de simplifier la mise en place d’applications distribuées
et concurrentes basée sur la JVM. Il gère donc les langages de programmations <em>Java</em> et <em>Scala</em>,
et est développé en Scala. Akka propose une résolution des problèmes de concurrence
via un système d’acteurs.</p>
<p>Chaque acteur propose des fonctionnalités, et peut communiquer avec les autres en
envoyant des messages.  Lorsqu’un acteur reçoit un message, il le traite, effectue des
actions et peut envoyer d’autres messages, instancier d’autres acteurs ou encore se stopper.</p>
<p>Chaque acteur est un client léger, qui possède son état et sa boîte aux lettres.
Lorsqu’un acteur plante, il est réinstancié automatiquement, dans le même état
qu’il était avant, et avec sa file de message, ce qui procure une haute disponibilité.
De plus, lorsqu’un acteur enfant plante, le parent est notifié, et il peut dès lors
prendre des mesures. Les messages sont asynchrones,ce qui permet de ne pas avoir
d’état bloquant en cas de latence réseau ou tout autre problème technique.
Akka s’occupe de distribuer les acteurs sur le cluster, ce qui permet d’avoir un
haut niveau d’abstraction pour le programmeur.</p>
</div>
</div>
</div>
<div class="section" id="id24">
<h1>Analyse<a class="headerlink" href="#id24" title="Lien permanent vers ce titre">¶</a></h1>
<p>Cette section vise à décrire le cadre logiciel dans lequel le travail sera effectué,
et à préciser les acteurs ainsi que leurs fonctions.</p>
<div class="section" id="woken">
<h2>Woken<a class="headerlink" href="#woken" title="Lien permanent vers ce titre">¶</a></h2>
<p>Woken <a class="reference internal" href="#wokenaxel" id="id25">[3]</a> est un service, utilisable via une <em>API REST</em>, qui fournit la possibilité
d’explorer les données (<em>data mining</em> en anglais) de la plateforme. Cette exploration
de données peut être de différentes natures, comme ériger un graphe qui permet
à l’utilisateur de visualiser les données, de demander une analyse statistique,
d’effectuer une expérience de classification via un des algorithmes de classification
fourni, ou encore une expérience de régression.</p>
<p>Chacune de ces explorations de données est effectuée sur un ensemble de données,
qui est qualifié par les champs configurés dans la <a href="#variables">Fig.  302</a> par l’utilisateur
de la plateforme.</p>
<p>Une expérience fournit des résultats au service demandeur, sous format PFA <a class="reference internal" href="#pfa" id="id26">[10]</a>,
qui est un format dont la synthaxe est basée sur <em>yaml</em>, mais dont la structure est
destinée à décrire des pipeline pour le data-mining.</p>
<p>Des requêtes HTTP sont mises à disposition dans le répertoire <code class="code docutils literal"><span class="pre">dev-debug/http</span></code>
ou <code class="code docutils literal"><span class="pre">dev-test/http</span></code> afin de permettre de se passer de l’interface graphique,
et de simplifier le développement.</p>
<div class="section" id="place-de-woken-dans-l-architecture">
<h3>Place de Woken dans l’architecture<a class="headerlink" href="#place-de-woken-dans-l-architecture" title="Lien permanent vers ce titre">¶</a></h3>
<p>Woken étant un service, il est concu pour être utiliser par d’autres services.
La <a href="#wokenarchiglobal">figure  312</a> présente une version simplifiée de l’architecture
de la plateforme MIP.</p>
<div class="figure align-center" id="id67">
<span id="wokenarchiglobal"></span><a class="reference internal image-reference" href="_images/woken_archi_global.png"><img alt="Architecture globale simplifiée de la plateforme MIP." src="_images/woken_archi_global.png" style="width: 350px;" /></a>
<p class="caption"><span class="caption-text">Architecture globale simplifiée de la plateforme MIP. Le <strong>Portal Frontend</strong> est le point d’accès
pour l’utilisateur. Il peut consulter les données et effectuer des expériences depuis celle-ci.
Le <strong>Portal Backend</strong> fournit les mécanismes de sécurité et d’accès aux bases de données, ainsi
que le passage des demandes à <strong>Woken</strong> si nécessaire. La base de données <strong>Science-db</strong> contient
les données des patients, tandis que la base de données <strong>Meta-db</strong> contient les descriptions
de chaque <em>feature</em> disponible dans la plateforme. Cette description permet de déterminer différentes
informations pour la plateforme telles que le type de données (nominale ou continue) ou l’unité de mesure.
Si il s’agit d’une demande nécessitant un algorithme, c’est <strong>Woken</strong>, l”<em>algorithm factory</em>,
qui va s’occuper de traiter les demandes. <strong>Woken</strong> peut lui-aussi accéder aux bases de données afin
d’appliquer ses algorithmes. Cette figure est une représentation simplifiée de
l’architecture, qui ne contient pas tous les intervenants de la plateforme, mais
uniquement ceux utilisés à cette échelle, dans le projet.</span></p>
</div>
<p>Lorsque l’utilisateur adresse une requête HTTP contenant une demande d’expérimentation,
le backend envoie une demande de <cite>mining</cite> à woken via une requête POST de la forme :</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>POST localhost:8087/mining/job <span class="se">\</span>
         variables:<span class="o">=</span><span class="s1">&#39;[{&quot;code&quot;:&quot;cognitive_task2&quot;}]&#39;</span> <span class="se">\</span>
         grouping:<span class="o">=</span><span class="s1">&#39;[]&#39;</span> <span class="se">\</span>
         covariables:<span class="o">=</span><span class="s1">&#39;[{&quot;code&quot;:&quot;score_math_course1&quot;}]&#39;</span> <span class="se">\</span>
         filters:<span class="o">=</span><span class="s1">&#39;[]&#39;</span> <span class="se">\</span>
         algorithm:<span class="o">=</span><span class="s1">&#39;{&quot;code&quot;:&quot;knn&quot;, &quot;name&quot;: &quot;KNN&quot;, &quot;parameters&quot;: []}&#39;</span>
</pre></div>
</div>
<p>Ce qui correspond aux paramétrage de l’expérience de l’utilisateur, comme présenté en
<a href="#variables">figure  302</a>.Woken traite la requête, effectue l’algorithme et retourne une réponse sous
format <em>PFA</em>. Le format de réponse n’est pas important dans le cadre de ce projet.</p>
<p>Il existe deux routes REST pour demander à Woken d’effectuer un travail :</p>
<ul class="simple">
<li><code class="code docutils literal"><span class="pre">/mining/job</span></code></li>
<li><code class="code docutils literal"><span class="pre">/mining/experiment</span></code></li>
</ul>
<p>Le <code class="code docutils literal"><span class="pre">/mining/job</span></code> permet de lancer un seul algorithme à la fois, et permet pas
de lancer des expériences utilisant la <em>cross-validation</em>, tandis que la route <code class="code docutils literal"><span class="pre">/mining/experiment</span></code>
permet la <em>cross-validation</em> et de lancer plusieurs algorithmes.</p>
<p>La requête pour une expérience via la route <code class="code docutils literal"><span class="pre">/mining/experiment</span></code> se présente sous la
forme :</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>POST localhost:8087/mining/experiment <span class="se">\</span>
         variables:<span class="o">=</span><span class="s1">&#39;[{&quot;code&quot;:&quot;cognitive_task2&quot;}]&#39;</span> <span class="se">\</span>
         grouping:<span class="o">=</span><span class="s1">&#39;[]&#39;</span> <span class="se">\</span>
         covariables:<span class="o">=</span><span class="s1">&#39;[{&quot;code&quot;:&quot;score_test1&quot;}, {&quot;code&quot;:&quot;college_math&quot;}]&#39;</span> <span class="se">\</span>
         filters:<span class="o">=</span><span class="s1">&#39;[]&#39;</span> <span class="se">\</span>
         algorithms:<span class="o">=</span><span class="s1">&#39;[{&quot;code&quot;:&quot;knn&quot;, &quot;name&quot;: &quot;knn&quot;, &quot;parameters&quot;: []}]&#39;</span> <span class="se">\</span>
         validations:<span class="o">=</span><span class="s1">&#39;[{&quot;code&quot;:&quot;kfold&quot;, &quot;name&quot;: &quot;kfold&quot;, &quot;parameters&quot;: [{&quot;code&quot;: &quot;k&quot;, &quot;value&quot;: &quot;2&quot;}]}]&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="fonctionnement-interne-de-woken">
<h3>Fonctionnement interne de Woken<a class="headerlink" href="#fonctionnement-interne-de-woken" title="Lien permanent vers ce titre">¶</a></h3>
<p>Woken a la responsabilité d’appliquer des algorithmes suite à la demande via l’une
des deux <a class="reference internal" href="#routesrest"><span class="std std-ref">routes REST</span></a> mises à disposition.</p>
<p>La <a href="#wokenarchiinternal">figure  313</a> présente les intervenants liés à <em>Woken</em> lors
d’une demande d’algorithme.</p>
<div class="figure align-center" id="id68">
<span id="wokenarchiinternal"></span><a class="reference internal image-reference" href="_images/woken_archi_internal.png"><img alt="Architecture  interne de woken." src="_images/woken_archi_internal.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Architecture «&nbsp;interne&nbsp;» de woken. Les intervenants ici présents
sont ceux qui sont directement utilisés par le service <em>Woken</em>.
Le service <strong>Woken</strong> en lui-même est généralement contenu dans un
container, mais il peut être en natif dans l’architecture, comme dans le cas de l’architecture <code class="code docutils literal"><span class="pre">dev-debug</span></code>
du projet. Il est responsable d’instancier des <strong>algorithmes</strong> contenus
dans des containers <em>Docker</em>, via <em>Chronos</em>. Si l’expérience utilisateur demande une <em>cross-validation</em>, un <strong>pool d’acteurs AKKA</strong>
s’occupant de cette tâche est instanciée au lancement de l’architecture, et sont prêts en tout temps à répondre à cette tâche.
Ce choix a été effectué afin d’éviter de devoir instancier ces acteurs
pour chaque demande, en prévision d’une forte charge sur la plateforme. Ces acteurs sont contenus dans un container <em>Docker</em>, ce
qui permet de mettre à l’échelle en cas de besoin. Le résultat de chaque expérience
est stocké dans la base de données <strong>Woken-DB</strong>, ce qui permet de récupérer
le fichier de définition <em>PFA</em> afin de reconstruire l’éxpérience et de la vérifier,
si besoin. Attention, les intervenants décrits ci-contre ne sont pas contenus
dans le projet <em>Woken</em>, mais bel et bien indépendants, et liés via la configuration <em>Docker-compose</em>.</span></p>
</div>
<p>Par rapport au code de <em>Woken</em>, le principal intervenant est le flux d’acteurs <em>Akka</em>,
implémenté dans le script <code class="code docutils literal"><span class="pre">/src/main/scala/core/coordinator.scala</span></code>. C’est celui-ci
qui recoit les expérimentations à effectuer. Celles-ci sont déterminées par un code
d’algorithme, des <em>features</em> concernées, les variables cibles ainsi que le modèle et
les hyperparamètres pour les expériences de <em>machine learning</em>.</p>
<p>Les acteurs <em>Akka</em> implémentés dans cette portion de code Scala héritent d’une méthodologie
FSM (Finite State Machine), ce qui rend les acteurs capables de se comporter comme un
automate à états finis. Les transition entre ces états s’effectuent via des événements
précis. Cette implémentation permet de mettre un acteur parent en attente des résultats
des acteurs enfants, de manière élégante et sans attente active bloquante.</p>
<p>Suivant la <a class="reference internal" href="#routesrest"><span class="std std-ref">route REST</span></a> en question, il existe deux flux possibles.</p>
<p>La route <code class="code docutils literal"><span class="pre">/mining/job</span></code> se contente de lancer un <cite>coordinatorActor</cite>, qui est un
acteur responsable de convertir un <cite>Job</cite> (<code class="code docutils literal"><span class="pre">case</span> <span class="pre">class</span></code> scala) en JSON mis en
forme selon le format d’entrée de Chronos, de lancer la requête à celui-ci, d’attendre
les résultats dans la base de données <em>Woken-DB</em>, de mettre en forme le résultat et
de le retourner au service demandeur.</p>
<p>La voie intéressante dans le cadre de ce projet est celle de <code class="code docutils literal"><span class="pre">/mining/experiment</span></code>.
Celle-ci a pour caractéristique de pouvoir gérer plusieurs algorithmes pour une expérimentation,
ainsi que de gérer la <em>cross-validation</em>.</p>
<p>Le flux de travail entre les acteurs peut être représenté comme montré sur la
<a href="#wokenactors">figure  314</a></p>
<div class="figure align-center" id="id69">
<span id="wokenactors"></span><a class="reference internal image-reference" href="_images/wokenactors.png"><img alt="Schéma des acteurs Akka du script coordinator.scala." src="_images/wokenactors.png" style="width: 650px;" /></a>
<p class="caption"><span class="caption-text">Schéma des acteurs Akka du script coordinator.scala. Les différents acteurs peuvent
instancier d’autres acteurs dynamiquement, ce qui permet de répondre à n’importe
quelle configuration d’expérimentation de l’utilisateur. Ce schéma correspond à
l’implémentation avant le début du projet. Il existe des <cite>coordinatorActor</cite> qui
ne sont pas documentés dans ce diagramme. Ils ont pour but d’envoyer un <cite>Job</cite> à
Chronos, et d’attendre les résultats du container dans la base de données. Ceci
induit qu’il n’y a pas de communication entre <em>Woken</em> et les containers. La cross-validation
n’est effectuée que si l’algorithme est défini dans <em>Woken</em> comme prédictif.
Les requêtes SQL sont envoyées aux configurations de Chronos (format JSON) sous
la forme de variables d’environnement. Il est prévu de limiter l’accès aux base
de données à l’avenir, en passant le dataset aux containers, plutôt que
de les laisser accéder directement aux bases de données.</span></p>
</div>
<p>Ce flux de travail comporte oblige deux problématiques de taille :</p>
<ul class="simple">
<li>Il est nécessaire d’attendre un résultat dans la base de données pour que les <cite>localCoordinatorActor</cite> détectent que le container a fourni un travail.</li>
<li>Il est nécessaire de passer par le mécanisme de <em>cross-validation</em> pour définir un score à une expérience. Ceci impose aussi un format <em>PFA</em> strict.</li>
</ul>
</div>
<div class="section" id="fonctionnement-actuel-des-containers-docker">
<h3>Fonctionnement actuel des containers Docker<a class="headerlink" href="#fonctionnement-actuel-des-containers-docker" title="Lien permanent vers ce titre">¶</a></h3>
<p>Actuellement, les containers utilisés par la plateforme Docker sont lancés via Chronos.
A partir d’une définition d’expérience au format <em>JSON</em>, on instancie un objet de définition
de cet algorithme en <code class="code docutils literal"><span class="pre">case</span> <span class="pre">classes</span></code> Scala. Depuis ces définitions de classes,
Woken sérialise en <cite>JSON</cite> correspondant au format attendu par Chronos, comme par exemple :</p>
<div class="highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;chronos&quot;</span><span class="p">,</span>
  <span class="nt">&quot;cpus&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="nt">&quot;mem&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
  <span class="nt">&quot;instances&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
  <span class="nt">&quot;container&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;DOCKER&quot;</span><span class="p">,</span>
    <span class="nt">&quot;docker&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;image&quot;</span><span class="p">:</span> <span class="s2">&quot;mesosphere/chronos&quot;</span><span class="p">,</span>
      <span class="nt">&quot;network&quot;</span><span class="p">:</span> <span class="s2">&quot;BRIDGE&quot;</span><span class="p">,</span>
      <span class="nt">&quot;portMappings&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="nt">&quot;containerPort&quot;</span><span class="p">:</span> <span class="mi">4400</span><span class="p">,</span>
          <span class="nt">&quot;hostPort&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
          <span class="nt">&quot;servicePort&quot;</span><span class="p">:</span> <span class="mi">4400</span><span class="p">,</span>
          <span class="nt">&quot;protocol&quot;</span><span class="p">:</span> <span class="s2">&quot;tcp&quot;</span>
        <span class="p">}</span>
      <span class="p">]</span>
    <span class="p">},</span>
    <span class="nt">&quot;volumes&quot;</span><span class="p">:</span> <span class="p">[]</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><em>Woken</em> est actuellement capable d’instancier autant de containers que demandent les utilisateurs.
Il s’occupe de générer des identifiants uniques comme <cite>id</cite> de tâche à Chronos,
de récolter chacun des résultats dans la base de données et de les mettre en relation avec
la bonne expérience.</p>
<p>Il n’est en revanche pas capable de communiquer avec un container. Une fois le fichier
de configuration <cite>JSON</cite> envoyé via une requête POST HTTP, il ne peut qu’attendre les résultats
dans la base de données.</p>
<p>Dans le cadre de notre nouveau flux, nous devons pouvoir attendre la fin du travail d’un
container, récupérer son résultat, puis adresser une deuxième requête utilisant le résultat précédemment
rendu.</p>
<p>Cette fonctionnalité, que l’on peut qualifier de container «&nbsp;interactifs&nbsp;», doit faire
l’objet de recherches. Docker est conçu pour être <em>stateless</em>. Quand un container meurt,
si il n’a pas de <em>Volume</em> configuré, le container n’a pas de moyen d’enregistrer l’état
dans lequel il était. Un <em>Volume</em> est un répertoire partagé entre le container et l’hôte.
Si il existe des fichiers dans le dossier au moment du montage du <em>Volume</em>, le container
y aura accès. Si le container meurt, le contenu du <em>Volume</em> reste.</p>
</div>
<div class="section" id="tests-preliminaires-avec-tpot">
<h3>Tests préliminaires avec TPOT<a class="headerlink" href="#tests-preliminaires-avec-tpot" title="Lien permanent vers ce titre">¶</a></h3>
<p>Des tests ont été effectués avec TPOT afin de déterminer son utilisabilité.
Dans le cadre de du projet, le plus important était de pouvoir:</p>
<ul class="simple">
<li>Travailler avec le dataset du projet;</li>
<li>Pouvoir extraire le meilleure pipeline à la fin de l’optimisation;</li>
<li>Obtenir les scores;</li>
<li>Reconstruire le pipeline à partir via Scikit-learn.</li>
</ul>
<p>Mais aussi, si possible:</p>
<ul class="simple">
<li>Déterminer les <em>features</em> construites;</li>
<li>Déterminer l’importance de chaque feature.</li>
<li>Déterminer l’exploitabilité de l’export implémenté dans TPOT.</li>
</ul>
<p>Des tests <a class="reference internal" href="#tpottests" id="id27">[29]</a> ont été implémentés, et une issue <a class="reference internal" href="#tpotissue" id="id28">[31]</a> a été
adressée sur le projet afin de vérifier les points délicats.</p>
<p>A la fin de ces tests, il s’avère que :</p>
<ul class="simple">
<li>Il est possible de récupérer le meilleur pipeline trouvé, avec les hyperparamètres du modèle, ainsi que son score;</li>
<li>Il est possible d’enregistrer un pipeline sous forme de texte, et de le ré-instancier en objet Scikit-learn utilisable pour des prédictions;</li>
<li><em>TPOT</em> n’est pas en mesure de mettre à disposition la selection, la construction et la normalisation de features. Celles-ci sont données par le modèle;</li>
<li>L’export n’est pas utilisable dans notre contexte;</li>
<li>Il est possible de travailler avec le dataset du projet.</li>
</ul>
<p>A la fin de cette analyse, les attentes envers TPOT dans le cadre du projet sont atteintes.</p>
</div>
<div class="section" id="le-cas-de-marathon">
<h3>Le cas de Marathon<a class="headerlink" href="#le-cas-de-marathon" title="Lien permanent vers ce titre">¶</a></h3>
<p>Durant ce projet, la substition de <em>Chronos</em> par <em>Marathon</em> a été explorée. La raison
est que <em>Chronos</em> n’est pas diretement lié à la <em>Mesosphere</em>, et que son développement
n’est pas assuré sur le long terme. Une fois intégré dans l’architecture, il s’est avéré que
Marathon ne répond qu’à la problématique des services de longues durées.</p>
<p><em>Metronome</em> <a class="reference internal" href="#metronome" id="id29">[1]</a> est destiné à être le remplacant de <em>Marathon</em>, mais il n’est actuellement
pas assez abouti pour être incorporé à l’architecture.</p>
</div>
</div>
</div>
<div class="section" id="conception">
<h1>Conception<a class="headerlink" href="#conception" title="Lien permanent vers ce titre">¶</a></h1>
<p>Cette section ne décrit que les choix de conceptions qui ont étés implémentés.</p>
<p>A partir de l’analyse effectuée au chapitre <span class="xref std std-ref">analyse</span>, il est possible de concevoir
la nouvelle architecture pour résoudre les problèmatiques connues qui sont :</p>
<ul class="simple">
<li>Mettre en place un flux qui se passe de l’attente des résultats des containers dans la base de données;</li>
<li>Mettre en place un container qui accepte plusieurs points d’entrées;</li>
<li>Se passer de la mise en forme de PFA imposée dans le flux actuel.</li>
</ul>
<div class="section" id="modification-globale-du-workflow-woken">
<h2>Modification globale du workflow Woken<a class="headerlink" href="#modification-globale-du-workflow-woken" title="Lien permanent vers ce titre">¶</a></h2>
<p>Sans parler directement de la modifications des acteurs <em>Akka</em>, il est intéressant
de présenter une vue d’ensemble des intervenants dans la problématique du projet,
et de définir les rôles qu’ils remplissent dans cette nouvelle conception.</p>
<p>La <a href="#conceptionflow">figure  315</a> présente une représentation du flux imaginé.
Elle est volontairement présentée en premier, et avec un haut niveau d’abstraction,
afin de définir la conception des différentes parties qui la constituent. Etant donné
que les restrictions sont fortement liées à Docker et à son fonctionnement, la suite
de la conception est rédigée en parcourant les intervenants de droite à gauche.</p>
<div class="figure align-center" id="id70">
<span id="conceptionflow"></span><a class="reference internal image-reference" href="_images/conceivedworkflow.png"><img alt="Schéma du nouveau workflow global." src="_images/conceivedworkflow.png" style="width: 450px;" /></a>
<p class="caption"><span class="caption-text">Schéma représentant les intéractions entre les différents intervenants, pour la conception retenue.
Les titres de colonnes définissent la technologie responsable des tâches qui sont
dans la colonne. Pour le cas d’Akka, cette représentation ne correspond pas à un
diagramme d’acteur. Ce nouveau flux utilise les <em>volumes</em> de Docker afin de faire
persister les résultats d’entraînements et de prédicats.</span></p>
<div class="legend">
</div>
</div>
</div>
<div class="section" id="conception-pour-tpot">
<h2>Conception pour TPOT<a class="headerlink" href="#conception-pour-tpot" title="Lien permanent vers ce titre">¶</a></h2>
<p>Sans se soucier de la problématique <em>Docker</em>, le script <em>Python</em> doit pouvoir fournir deux
méthodes, <code class="code docutils literal"><span class="pre">train</span></code> et <code class="code docutils literal"><span class="pre">test</span></code>.</p>
<p>La méthode <code class="code docutils literal"><span class="pre">train</span></code> s’occupe de :</p>
<ul class="simple">
<li>Charger les paramètrages via un fichier <em>JSON</em> ;</li>
<li>Charger le dataset;</li>
<li>Transformer le dataset pour qu’il soit utilisable par TPOT;</li>
<li>Séparer le dataset en <em>training set</em> et <em>validation test</em>;</li>
<li>Lancer l’entraînement de TPOT avec les données correspondantes;</li>
<li>Récupérer le meilleur pipeline et l’écrire dans un fichier texte.</li>
</ul>
<p>La méthode <code class="code docutils literal"><span class="pre">test</span></code> s’occupe de :</p>
<ul class="simple">
<li>Charger le meilleur pipeline entraîné via un fichier <em>JSON</em>;</li>
<li>Reconstruire le pipeline en objet <em>Scikit-Learn</em>;</li>
<li>Effectuer des prédicats sur les données passées en paramètres;</li>
<li>Ecrire les scores dans un fichier texte.</li>
</ul>
</div>
<div class="section" id="systeme-de-containers-interactifs">
<h2>Système de containers interactifs<a class="headerlink" href="#systeme-de-containers-interactifs" title="Lien permanent vers ce titre">¶</a></h2>
<p>Un container n’est normalement pas conçu pour faire persister des données sur son état.
Lors de l’arrêt d’un container, l’hôte n’enregistre en général pas de données sur son
état avant de l’arrêter. Il est tout de même possible de partager des informations entre
un container et l’hôte via le système de volumes <a class="reference internal" href="#dockervolumes" id="id30">[16]</a>.</p>
<p>Un volume est un répertoire partagé entre l’hôte et le container. Le lien entre l’hôte
et le container se fait au moment du lancement du container via la commande code:<cite>docker run -v containerpath:hostpath imagename args</cite>.</p>
<p>Si le répertoire contient des fichiers au moment du lien, les fichiers sont directement
accessibles par celui-ci. Le container peut manipuler des fichiers dans ce repertoire
comme il le désire. Une fois le container arrêté, les fichiers crées dans ce répertoire
persistent pour l’hôte.</p>
<p>Partant de ce principe, il est imaginable de créer un container dont le script effectue
un travail différent selon la méthode d’appel, et les fichiers contenus dans le répertoire.</p>
<p>Pour ce faire, il est possible de définir un script qui redirige vers la bonne méthode
du script python en fontion de l’argument <cite>commande</cite> passé en paramètre lors de l’instanciation
du container. Pour rappel, ce paramètre se présente ainsi <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">parametres</span> <span class="pre">nomducontainer</span> <span class="pre">commande</span></code>.</p>
<p>Une autre méthode explorée (et testée) est de lancer le container dans un mode d’attente,
sans lancer le script, via la commande <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">containername</span></code>, puis de demander
l’exécution d’un entrypoint via la méthode <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">exec</span> <span class="pre">containername</span> <span class="pre">commande</span></code>, où
commande correspond au nom défini dans l’entrypoint.</p>
<p>On connaît déjà à ce stade un <strong>problème</strong> lié à la nature distribuée de l’architecture.
L’utilisation des <em>volumes</em> docker utilise un répertoire hôte pour effectuer le lien.
Chronos repose sur Mesos afin de répartir la charge en fonction des ressources, ce qui fait
que l’on ne contrôle pas la machine physique sur laquelle le fichier est crée.
Etant donné qu’il n’y a pas de <strong>système de fichier distribué</strong> dans la plateforme, il
est nécessaire que, pour une expérience, l’appel de l’entraînement et des prédicats
soient effectués sur <strong>la même machine physique</strong>.</p>
<p>Ce problème, bien que connu, n’est pas prioritaire dans le cadre de ce projet. L’utilisation
des <em>volumes Docker</em> n’est pas définitive, il est prévu de mettre en place une communication
directe entre l’acteur <em>Akka</em> et le container. La principale option semble être la mise
en place d’un système de queues de messages entre l’acteur <em>Akka</em> et le container <em>Docker</em> lié,
par exemple via une bibliothèque comme ZeroMQ <a class="reference internal" href="#zeromq" id="id31">[37]</a>. Le but de ce projet est
de faire une expérience scientifique sur l’apport de l” <em>automated machine learning</em>
dans le cadre de la plateforme.</p>
</div>
<div class="section" id="id32">
<h2>Chronos<a class="headerlink" href="#id32" title="Lien permanent vers ce titre">¶</a></h2>
<p>Chronos est un logiciel que l’on se contentera d’utiliser depuis une
image Docker, il n’y a pas de conception liée à cette partie. Il faut néanmoins
observer précisément le format du JSON à fournir en entrée pour permettre de donner
la configuration complète et correcte pour notre container qui sera lancé.</p>
<p>Il a déjà été vérifié que Chronos, dans sa version <cite>3.0.2</cite>, permet de lancer un
container avec des volumes, des variables d’environnement, et un entrypoint.</p>
</div>
<div class="section" id="id33">
<h2>Akka<a class="headerlink" href="#id33" title="Lien permanent vers ce titre">¶</a></h2>
<p>Le flux d’acteurs présenté à la figure <a href="#wokenactors">figure  314</a> est modifié afin
de répondre au nouveau container «&nbsp;interactif&nbsp;» lié à Docker. La <a href="#newinteractiveactors">figure  316</a>
présente le flux de travail alternatif conçu.</p>
<div class="figure align-center" id="id71">
<span id="newinteractiveactors"></span><a class="reference internal image-reference" href="_images/modifieddiagramactorscoordinator.png"><img alt="Schéma de la nouvelle conception d'acteurs pour le nouveau flux interactif." src="_images/modifieddiagramactorscoordinator.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Schéma de la nouvelle conception d’acteurs pour le nouveau flux interactif.
Un seul acteur suffit à effectuer les deux appels consécutifs du container TPOT.
Le nouvel acteur commence par définir les conditions d’entraînement pour l’optimisation
du pipeline dans le cadre de l’expérience. Il doit définir les features, les targets,
lier les meta-données pour déterminer s’il s’agit d’une expérience de classification
ou de régression. Le passage via les variables d’environnement des configurations des
bases de données évitent une configuration trop restrictive en interne au container.
Les états d’attentes peuvent être implémentés en vérifiant la présence du fichier sur
le volume ou demander via des requêtes <code class="code docutils literal"><span class="pre">GET</span></code> sur la route du code:<cite>job</cite> de <em>Chronos</em>
l’état de la tâche. La deuxième méthode est recommandée, car elle permet de récupérer
le code de réussite ou d’erreur de Chronos. La seule présence d’un fichier sur le
disque ne permet pas de dire si le travail est complet. La mise en forme des prédicats
pour le retour à l’AlgorithmActor n’est pas encore déterminé.</span></p>
</div>
</div>
</div>
<div class="section" id="implementation-realisee">
<h1>Implémentation réalisée<a class="headerlink" href="#implementation-realisee" title="Lien permanent vers ce titre">¶</a></h1>
<p>Cette section précise l’implémentation réalisée dans le cadre de ce projet. Comme toutes
les autres sections, elle ne présente que la version finale, et pas tous les tests et le
cheminement effectués.</p>
<div class="section" id="presentation-des-taches">
<h2>Présentation des tâches<a class="headerlink" href="#presentation-des-taches" title="Lien permanent vers ce titre">¶</a></h2>
<p>Afin de faciliter la lecture, ce chapitre sera présenté en suivant la numérotation de
la représentation de la <a href="#tasksbreakdown">figure  317</a>.</p>
<div class="figure align-center" id="id72">
<span id="tasksbreakdown"></span><a class="reference internal image-reference" href="_images/ImplementationRepresentation.png"><img alt="Représentation graphique des tâches réalisées." src="_images/ImplementationRepresentation.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Représentation graphique des tâches réalisées. Elles sont volontairement
traitées de droite à gauche, car il y a une imbrication ou une utilisation toujours
dirigée vers la gauche, ce qui implique que les restrictions proviennent toujours
d’un composant plus à gauche. La taille des blocs n’a pas de lien avec la durée
d’implémentation d’une tâches.</span></p>
</div>
</div>
<div class="section" id="id34">
<h2>TPOT<a class="headerlink" href="#id34" title="Lien permanent vers ce titre">¶</a></h2>
<p>Cette section présente les points importants de l’implémentation du script <cite>Python</cite>
qui implémente la solution d’optimisation de pipeline automatique de <cite>TPOT</cite>.</p>
<p>Le script implémenté est disponible sur <em>Github</em> <a class="reference internal" href="#tpotcode" id="id35">[28]</a>.</p>
<div class="section" id="tache-1-recuperation-du-meilleur-pipeline">
<h3>Tâche 1 : Récupération du meilleur pipeline<a class="headerlink" href="#tache-1-recuperation-du-meilleur-pipeline" title="Lien permanent vers ce titre">¶</a></h3>
<p>Le meilleur est disponible après l’optimisation du pipeline via TPOT. La récupération
se fait via la variable interne <code class="code docutils literal"><span class="pre">_optimized_pipeline</span></code> de l’objet <cite>TPOTClassifier</cite>
ou <code class="code docutils literal"><span class="pre">TPOTRegressor</span></code>. L’accès via les variables internes, spécifiées via le «&nbsp;_&nbsp;»
avant le nom de la variable, est généralement contraire aux conventions de codage <cite>Python</cite>,
mais il a été confirmé dans une issue <a class="reference internal" href="#tpotissue" id="id36">[31]</a> par l’auteur du code que
c’est pour l’instant la seule méthode, mais une récente issue <a class="reference internal" href="#tpotissuerefactor" id="id37">[24]</a>
montre que les développeurs ont conscience de cette mauvaise pratique.</p>
<p>Si le changement est effectué dans la même <em>release</em>, il faudra modifier le code du
script.</p>
</div>
<div class="section" id="tache-2-liaison-de-la-bdd-du-chuv-mise-en-forme-du-dataset-pour-tpot-et-decoupage-du-dataset">
<h3>Tâche 2 : Liaison de la BDD du CHUV, mise en forme du dataset pour TPOT et découpage du dataset<a class="headerlink" href="#tache-2-liaison-de-la-bdd-du-chuv-mise-en-forme-du-dataset-pour-tpot-et-decoupage-du-dataset" title="Lien permanent vers ce titre">¶</a></h3>
<p>Le script <code class="code docutils literal"><span class="pre">database_connector.py</span></code>, fourni par le CHUV avec les images de base
<em>Docker</em> <cite>Python</cite> pour l’implémentation de nouveaux algorithme, se base sur les variables
d’environnement du container. Le script permet d’effectuer des requêtes <cite>SQL</cite> directement
sur la <cite>Science-db</cite>, en <cite>SELECT</cite> uniquement, et sur la <cite>Woken-DB</cite> en écriture afin
d’inscrire les résultats d’expériences.</p>
<p>Le dataset est transformé en <cite>array</cite> <em>numpy</em> après la récupération des <em>records</em> de
la requête, afin de correspondre au type attendu par TPOT. Ceci est appliqué pour les
<em>features</em>, mais aussi pour les <em>targets</em>.</p>
</div>
<div class="section" id="tache-3-analyse-du-type-de-features">
<h3>Tâche 3 : Analyse du type de features<a class="headerlink" href="#tache-3-analyse-du-type-de-features" title="Lien permanent vers ce titre">¶</a></h3>
<p>Il est possible de récupérer le type des features (nominal ou continu) via la
méthode <cite>var_type</cite> du script <cite>database_connector.py</cite>. Ces types sont récupérés
depuis les variables d’environnement du container.</p>
<p>Cette fonctionnalité n’est pas encore implémentée. Il faudra tester toutes les features,
et, si il n’y a que des features de type continues, instancier un <cite>TPOTRegressor</cite>,
et si non, instancier un <cite>TPOTClassifier</cite>. Le reste du script ne change pas.</p>
</div>
<div class="section" id="tache-4-reconstruction-du-pipeline-via-la-description-texte-cree-par-tpot">
<h3>Tâche 4 : Reconstruction du pipeline via la description texte crée par TPOT<a class="headerlink" href="#tache-4-reconstruction-du-pipeline-via-la-description-texte-cree-par-tpot" title="Lien permanent vers ce titre">¶</a></h3>
<p>Depuis l’enregistrement sous format d’une chaîne de caratères via la phase de <em>training</em>,
il est possible de reconstruire le pipeline en objet <em>scikit-learn</em> via la <em>toolbox</em> de TPOT
via la directive <code class="code docutils literal"><span class="pre">tpot._toolbox.compile(expr=pipeline)</span></code>. Dès lors, il est
possible de fitter le pipeline par rapport au même training et test set que lors
de la phase de <cite>training</cite>. Il est facile de récupérer le même découpage du training
test et du test set en définissant la <cite>seed</cite> pour la méthode de découpage du dataset,
soit <code class="code docutils literal"><span class="pre">train_test_split(X,y,</span> <span class="pre">random_state</span> <span class="pre">=</span> <span class="pre">42)</span></code> qui est fournie par <em>scikit-learn</em>.</p>
</div>
<div class="section" id="tache-5-retour-des-predictions">
<h3>Tâche 5 : Retour des prédictions<a class="headerlink" href="#tache-5-retour-des-predictions" title="Lien permanent vers ce titre">¶</a></h3>
<p>Pour l’instant, le retour des prédictions se fait au format JSON en sérialisant l’objet
<cite>array</cite> de <cite>numpy</cite>. Ce formatage de retour n’est pas définitif, mais il n’as pas été
encore précisé comment nous allons implémenter la liaison du retour du containeur au flux
<em>Woken</em>. Dans tous les cas, l’acteur, après la récupération des scores, devra
s’occuper du formatage pour permettre de retourner au <em>AlgorithmActor</em> qui lui a
confié le <em>job</em> pour l’algorithme <em>TPOT</em>.</p>
</div>
</div>
<div class="section" id="id38">
<h2>Docker<a class="headerlink" href="#id38" title="Lien permanent vers ce titre">¶</a></h2>
<p>Une fois le script TPOT fonctionnel en stand-alone, il est possible d’intégrer ce
script dans les images de créations d’algorithmes pour la plateforme fournies par
le CHUV <a class="reference internal" href="#dockerimages" id="id39">[11]</a>.</p>
<p>La copie du script dans le container s’effectue via le Dockerfile, en utilisant
la directive <code class="code docutils literal"><span class="pre">COPY</span></code>. Le script de connexion <code class="code docutils literal"><span class="pre">database_connector.py</span></code>
est lui aussi copié en interne au container.</p>
<p>Dans le cadre du projet, Captain <a class="reference internal" href="#captain" id="id40">[34]</a> est utilisé afin de générer des images
taguées par leur numéro de commit. On utilise le script <code class="code docutils literal"><span class="pre">build.sh</span></code> pour générer
l’image. Le nom de l’image est contenu dans le fichier de définition <code class="code docutils literal"><span class="pre">captain.yml</span></code>.</p>
<p>Le fichier <cite>README</cite> du repository de travail <a class="reference internal" href="#dockerimages" id="id41">[11]</a> contient les commandes
pour tester le container interactif.</p>
<p>Une version a été publiée sur Docker-Hub <a class="reference internal" href="#dockerhubtpot" id="id42">[27]</a> afin de tester l’application du container
dans le cadre de Woken.</p>
<p>L’installation de la dépendance TPOT via <em>pip</em> est effectuée directement dans le Dockerfile.</p>
<div class="section" id="tache-6-implementation-dun-container-stateful">
<h3>Tâche 6 : Implémentation d’un container stateful<a class="headerlink" href="#tache-6-implementation-dun-container-stateful" title="Lien permanent vers ce titre">¶</a></h3>
<p>Le point principal d’implémentation de la partie Docker réside dans le fait de pouvoir
conserver des informations entre la phase de <em>training</em> et la phase de <em>test</em> (qui correspond
aux prédicats).</p>
<p>Au niveau <em>Python</em>, entre deux appels successifs sur le script de <em>TPOT</em>, les variables
n’ont pas de persistance, car les variables sont supprimées à la fin de l’exécution de la
méthode appellée. Il est donc nécessaire d’enregistrer de manière persistante le résultat
à la fin de chaque appel d’une des deux méthodes.</p>
<p>Dès lors, deux implémentations sont possibles :</p>
<ul class="simple">
<li>Attente active</li>
<li>Démarrage avec un état déterminé.</li>
</ul>
<p><strong>Attente active</strong></p>
<p>Un container est démarré via la méthode <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span></code> en mode d’attente.
Il ne contient qu’un processus d’attente de travail.</p>
<p>Lorsqu’il reçoit une demande de training via la commande <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">exec</span> <span class="pre">containername</span> <span class="pre">train</span></code>,
le processus d’attente crée un processus enfant, qui correspond à l’appel <em>Python</em> sur le script
TPOT. Le script python va chercher les informations sur la description de l’expérience, soit dans
les variables d’environnement, soit dans le fichier de définition du <em>volume</em>.Lorsqu’il a fini l’entrainement,
il inscrit le meilleur pipeline dans fichier texte, dans un répertoire local, non accessible par
l’hôte.</p>
<p>Le processus enfant est supprimé, et le processus d’attente reste en vie.</p>
<p>Lors de la demande de prédicats via la commande <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">exec</span> <span class="pre">containername</span> <span class="pre">test</span></code>,
un nouveau processus enfant est crée. Il effectue les prédicats et les mets à disposition
dans le <em>volume</em> partagé par l’hôte.</p>
<p>Une nouvelle demande de travail peut en tout temps être effectuée, car le processus
d’attente est actif tant que le container n’est pas stoppé.</p>
<p>Cette implémentation doit être faite en étant attentif au problème de <cite>PID 1</cite> et de processus
zombies <a class="reference internal" href="#zombiesdocker" id="id43">[17]</a>, problème bas-niveau Linux connu et géré dans toutes les distribution, mais qui n’est
pas nativement appliqué dans le cadre de Docker. Pour résumer simplement ce problème,
le processus avec le <cite>PID 1</cite> est responsable de la suite des signaux bas-niveau à tous
les enfants, et de récupérer les processus orphelins qui peuvent survenir dans les
cas ou un parent n’attend pas la fin du travail du sous-processus enfant.</p>
<p>Ces problématiques créent des processus zombies, qui peuvent saturer l’utilisation
de <cite>PID</cite> et provoquer un freeze total de la machine.</p>
<p>Ce problème est réglé dans l’implémentation <a class="reference internal" href="#tiniimplementation" id="id44">[30]</a> effectuée via
l’utilisation de <cite>tini</cite> <a class="reference internal" href="#tini" id="id45">[25]</a>.</p>
<p>Cette implémentation, bien que fonctionnelle via la ligne de commande <em>Docker</em>,
n’est pas utilisable via Chronos, car il ne gère par l’envoi de commande <code class="code docutils literal"><span class="pre">exec</span></code>
après le lancement d’un container.</p>
<p><strong>Démarrage avec un état déterminé</strong></p>
<p>Dans cette implémentation, le container reçoit lui-aussi toutes les informations nécessaires
au mode dans lequel il est appellé. En revanche, il se lance directement en appellant
un travail via la méthode <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">containername</span> <span class="pre">commande</span></code>, où <code class="code docutils literal"><span class="pre">commande</span></code>
peut prendre les valeurs <code class="code docutils literal"><span class="pre">train</span></code> et <code class="code docutils literal"><span class="pre">test</span></code>.</p>
<p>Etant donné que le container meurt à la fin de l’éxécution du script, il est nécessaire
d’enregistrer toutes les sorties qui sont nécessaires au prochain appel sur le <em>volume</em>
partagé entre l’hôte et le container. Un appel sur la méthode <code class="code docutils literal"><span class="pre">test</span></code> doit être lié
au même <em>volume</em> que celui qui a effectué la phase d’entraînement.</p>
<p>Cette méthode est celle de l’implémentation finale, car elle permet d’être compatible
avec les restrictions de Chronos, qui ne permet d’envoyer des commandes <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span></code>.</p>
</div>
<div class="section" id="tache-7-gestion-des-entrypoints">
<h3>Tâche 7 : Gestion des entrypoints<a class="headerlink" href="#tache-7-gestion-des-entrypoints" title="Lien permanent vers ce titre">¶</a></h3>
<p>La définition des entrypoints est effectuée en donnant dans le Dockerfile la commande
<code class="code docutils literal"><span class="pre">ENTRYPOINT</span> <span class="pre">[/docker-entrypoint.sh]</span></code>, où <code class="code docutils literal"><span class="pre">docker-entrypoint.sh</span></code> est un
script bash de la forme:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>

<span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	<span class="nb">echo</span> <span class="s2">&quot;Running statefull docker container in training mode...&quot;</span>
	python main.py train
<span class="k">fi</span>


<span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span> <span class="o">=</span> <span class="s2">&quot;test&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	<span class="nb">echo</span> <span class="s2">&quot;Running statefull docker container in test mode...&quot;</span>
	python main.py <span class="nb">test</span>
<span class="k">fi</span>
</pre></div>
</div>
<p>Le paramètre <code class="code docutils literal"><span class="pre">commande</span></code> du <code class="code docutils literal"><span class="pre">docker-run</span></code> est automatiquement transmis
à ce script, qui défini le point d’entrée du script python à appeler. En cas de
commande non reconnue, le container n’effectuera pas d’appel au script, et ne plantera
pas.</p>
</div>
<div class="section" id="tache-8-variables-denvironnements">
<h3>Tâche 8 : Variables d’environnements<a class="headerlink" href="#tache-8-variables-denvironnements" title="Lien permanent vers ce titre">¶</a></h3>
<p>Les variables d’environnement sont toutes passées par le demandeur de l’algorithme
du container. Elles sont passées au moment de l’appel de la méthode de lancement de celui-ci
via la synthaxe <code class="code docutils literal"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--env</span> <span class="pre">cle=&quot;valeur&quot;</span></code>. Il est possible d’en stipuler
autant que besoin au lancement, et celles-ci sont accessibles dans le container comme
des variables d’environnement standard Linux, bien que leur portée soit locale au
container.</p>
</div>
<div class="section" id="tache-9-gestion-des-codes-derreurs">
<h3>Tâche 9 : Gestion des codes d’erreurs<a class="headerlink" href="#tache-9-gestion-des-codes-derreurs" title="Lien permanent vers ce titre">¶</a></h3>
<p>Pour la gestion des erreurs dans un container Docker, il faut prendre en compte
plusieurs niveaux auxquels celle-ci peuvent intervenir :</p>
<ul class="simple">
<li>Au niveau du script exécuté en interne;</li>
<li>Au niveau de la redirection des actions via les entrypoints;</li>
<li>Au moment du lancement du container.</li>
</ul>
<p>Les exceptions dans le script TPOT sont gérées, et renvoyées via la méthode traditionnelle
de <em>Python</em> <code class="code docutils literal"><span class="pre">sys.exit(code)</span></code>.</p>
<p>Ceux-ci sont renvoyées au script <em>bash</em> <code class="code docutils literal"><span class="pre">entrypoint.sh</span></code>,
qui s’est occupé d’appeler le script.</p>
<p>Les codes d’erreurs au moment de l’exécution, généralement générés par une erreur
de configuration, sont traités nativement par <cite>Docker</cite>.</p>
<p>Le script intérmédiaire <code class="code docutils literal"><span class="pre">entrypoint.sh</span></code> coupe actuellement le flux d’erreur,
car il ne retransmet pas les codes générés par le script <em>Python</em>. Ce problème est
réellement handicapant, car si une exception intervient dans le code, on ne peut
pas la retrouver en dehors du container, y compris avec les <cite>Docker logs</cite>.</p>
<p>Un travail supplémentaire doit être effectué pour que le script <code class="code docutils literal"><span class="pre">entrypoint.sh</span></code>
puisse retourner le code d’erreur au container, et inscrire les exception dans les logs.</p>
<p>Cette fonctionnalité n’a pas été implémentée par manque de temps.</p>
</div>
<div class="section" id="tache-10-connexion-aux-bases-de-donnees">
<h3>Tâche 10 : Connexion aux bases de données<a class="headerlink" href="#tache-10-connexion-aux-bases-de-donnees" title="Lien permanent vers ce titre">¶</a></h3>
<p>Etant donné que le script <em>Python</em> est désormais intégré dans le container,
l’accès à la base de données doit s’effectuer entre deux containers.
La configuration des bases de données sont passées via des variables d’environnement.
La configuration correcte du réseau, décrite dans le fichier <em>docker-compose.yml</em> de
l’architecture, est essentielle pour que les bases de données soient accessibles via
le container. Ces points sont traités dans la partie architecture de ce chapitre.</p>
</div>
</div>
<div class="section" id="id46">
<h2>Chronos<a class="headerlink" href="#id46" title="Lien permanent vers ce titre">¶</a></h2>
<p>Ce chapitre décrit la méthodologie de mise en place du passage de l’Instanciation
du container <em>Docker</em> <em>TPOT</em> de la ligne de commande Docker au lancement via Chronos.
hbpmip/woken-validation:AutoML
Chronos se base sur un fichier JSON pour définir la configuration d’une tâche.
Chronos a la fâcheuse manie à ne pas générer de code d’erreur en cas de format incorrect
du fichier JSON. Il remplace systèmatiquement la partie en question par une configuration
par défaut, ce qui rend le débuggage complexe.</p>
<p>Pour régler ce problème le plus directement possible, l’implémentation a été effectuée
tout d’abord via l’interface graphique. Une fois que le container a eu toutes les informations
correctement configurée pour qu’il puisse réaliser le travail en interne, la configuration
JSON a été enregistrée, et envoyée sur l’API en requête <cite>HTTP POST</cite> via <em>Woken</em>, afin de
découpler au maximum les sources de problèmes.</p>
<div class="section" id="tache-11-instanciation-du-container-personnalise-via-le-gui">
<h3>Tâche 11 : Instanciation du container personnalisé via le GUI<a class="headerlink" href="#tache-11-instanciation-du-container-personnalise-via-le-gui" title="Lien permanent vers ce titre">¶</a></h3>
<p>Chronos fourni une interface graphique présentée en <a href="#chonosguijson">figure  318</a></p>
<div class="figure align-center" id="id73">
<span id="chonosguijson"></span><a class="reference internal image-reference" href="_images/chronos_json_gui.png"><img alt="Interface graphique de configuration JSON d'une tâche Chronos." src="_images/chronos_json_gui.png" style="width: 300px;" /></a>
<p class="caption"><span class="caption-text">Interface graphique de configuration JSON d’une tâche Chronos.</span></p>
</div>
<p>Il est possible de tester tous les points spécifiques au container TPOT, telles que
la définition de <em>volumes</em>, le passage de variables d’environnement, ainsi que le format
pour la commande pour lancer correctement le</p>
</div>
<div class="section" id="tache-12-instanciation-du-container-via-une-requete-post-avec-un-fichier-json">
<h3>Tâche 12 : Instanciation du container via une requête POST avec un fichier JSON<a class="headerlink" href="#tache-12-instanciation-du-container-via-une-requete-post-avec-un-fichier-json" title="Lien permanent vers ce titre">¶</a></h3>
<p>Dès que le format JSON a été défini avec la tâche 13, l’envoi de ce fichier via une
requête <code class="code docutils literal"><span class="pre">HTTP</span> <span class="pre">POST</span></code> via curl a été testée. Celle-ci fonctionne comme prévu, en
l’adressant à l’url <code class="code docutils literal"><span class="pre">127.0.0.1:4400/v1/scheduler/iso8601</span></code>, mais aussi sur la
version 2.5 de Chronos, actuellement implémentée en production dans le projet.
L’ancienne version de Chronos utilise la route <code class="code docutils literal"><span class="pre">127.0.0.1:4400/scheduler/iso8601</span></code>.</p>
</div>
</div>
<div class="section" id="id47">
<h2>Akka<a class="headerlink" href="#id47" title="Lien permanent vers ce titre">¶</a></h2>
<p>Etant donné que l’instanciation du container TPOT est possible via Chronos, il est
possible d’implémenter le flux d’acteur nécessaire pour effectuer le travail présenté
à la <a href="#newinteractiveactors">figure  316</a>.</p>
<p>Cette partie est plus compliquée que les autres, car l’implémentation demande des connaissances
en <em>Scala</em>, en utilisant les définitions <em>AKKA</em> et en liant l’utilisation des automates
à états finis, choses totalement inconnues au début de ce projet.</p>
<p>Dans l’environnement de test <cite>dev-test</cite>, le code de <em>Woken</em> est compilé en <cite>jar</cite>, et
inclu dans un container <em>Docker</em>. Le <code class="code docutils literal"><span class="pre">docker-compose</span></code> de cet environnement
lance donc <em>Woken</em> dans un container. Le code prend plusieurs minutes à être compilées,
et les logs d’erreurs sont accessibles via <code class="code docutils literal"><span class="pre">docker-compose</span> <span class="pre">logs</span> <span class="pre">woken</span></code>, qui fournit
dans la ligne de commande, les exceptions qui sortent habituellement en console.
Il s’est vite avéré qu’il était trop compliqué pour chaque modification de tester
via se procédé, qui au complet prend une dizaine de minutes.</p>
<p>Il a été choisi créer un environnement <cite>dev-debug</cite> qui externalise <em>Woken</em> du container,
et le fait fonctionner en natif. Il est ainsi possible de débugger via les points
d’arrêts. La configuration a demandé un certain temps, car le <code class="code docutils literal"><span class="pre">docker-compose</span></code>
a du être finement configuré.</p>
<p>L’environnement est désormais disponible pour n’importe quel développeur externe.
Le document de configuration de l’environnement de développement est en cours de
rédaction.</p>
<div class="section" id="tache-13-mise-en-relation-du-validation-pool-akka">
<h3>Tâche 13 : Mise en relation du validation pool Akka<a class="headerlink" href="#tache-13-mise-en-relation-du-validation-pool-akka" title="Lien permanent vers ce titre">¶</a></h3>
<p>Etant donné que <em>Woken</em> a été passé en natif dans l’environnement <code class="code docutils literal"><span class="pre">dev-debug</span></code>,
le pool d’acteurs <em>Akka</em> de validation a du être adapté pour que la route <cite>/mining/experiment/</cite>
soit à nouveau fonctionnelle. Pour rappel, cette route est nécessaire pour que la
version avec cross-validation soit fonctionnelle. Bien qu’elle est coupée avant
l’utilisation du pool de validation dans ce projet, elle est néccessaire pour effectuer
une expérience de comparaison entre avec et sans optimisation de pipeline automatique.</p>
<p>Cette implémentation a été possible grace à une version spécifique de l’image
<code class="code docutils literal"><span class="pre">hbpmip/woken-validation:AutoML</span></code>.</p>
</div>
<div class="section" id="tache-14-mise-en-place-du-nouveau-flux-dacteurs-dans-woken-pour-traiter-nos-container-interactif">
<h3>Tâche 14 : Mise en place du nouveau flux d’acteurs dans Woken pour traiter nos container interactif<a class="headerlink" href="#tache-14-mise-en-place-du-nouveau-flux-dacteurs-dans-woken-pour-traiter-nos-container-interactif" title="Lien permanent vers ce titre">¶</a></h3>
<p>Actuellement, le nouvel acteur <code class="code docutils literal"><span class="pre">InteractiveActor</span></code> est implémenté pour remplacer
le <code class="code docutils literal"><span class="pre">ExperimentActor</span></code>, comme le suggère la <a href="#newinteractiveactors">figure  316</a>.</p>
<p>Au moment du rendu, la configuration du container pour l’entrainement est configuré.
Un fichier situé au chemin <code class="code docutils literal"><span class="pre">home/user/docker-volume</span></code> et contenant les informations
suivantes sont pour le moment nécéssaire :</p>
<div class="highlight-json"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;query_features&quot;</span><span class="p">:</span> <span class="s2">&quot;SELECT score_test1, stress_before_test1  from linreg_sample;&quot;</span><span class="p">,</span>
  <span class="nt">&quot;query_targets&quot;</span><span class="p">:</span> <span class="s2">&quot;SELECT score_math_course1 from linreg_sample;&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Il est à prévu de générer dynamiquement les répertoire pour les volumes, comme décrit dans la section
Architecture.</p>
<p>Pour le moment, le repertoire doit exister, et le fichier doit être valide.</p>
<p>Etant donné le manque de temps, la sérialisation de la configuration de classe Scala
est encore effectuée par un <code class="code docutils literal"><span class="pre">localCoordinatorActor</span></code>, ce qui implique qu’une fois
la requête envoyée à Chronos, l’acteur se met dans un état d’attente des résultats dans
la base de données, chose qui n’arrivera jamais étant donné que le container <em>TPOT</em>
ne répond pas comme ca.</p>
<p>la suite de l’implémentation sera effectuée en redéfinissant les <code class="code docutils literal"><span class="pre">localCoordinatorActor</span></code>
en une autre implémentation, qui permet de ne pas attendre de résultat dans la base de données.</p>
<p>Si cet acteur fontionne, il devient possible de passer dans l’état d’attente de résultat
de travail du container, géré par Chronos via la route <code class="code docutils literal"><span class="pre">/v1/scheduler/jobs/search?name=id</span></code>,
ou l”<cite>id</cite> est retourné au moment de la demande d’effectuer la tâche à Chronos.</p>
<p>Dès que la tâche est finie, il faut reconfigurer les définitions de classes pour lancer en
mode test, configurer le fichier en entrée sur le volume, et attendre à nouveau de <em>Chronos</em>
la confirmation de fin du travail du container.</p>
<p>Dès lors, le dernier état s’occupe de récupérer les prédicats, d’en tirer des métriques
et de les mettre en forme pour les transmettre à l”<cite>AlgorithmActor</cite> qui a appelé l’acteur traitant
de <em>TPOT</em>.</p>
</div>
</div>
<div class="section" id="id48">
<h2>Scala<a class="headerlink" href="#id48" title="Lien permanent vers ce titre">¶</a></h2>
<p>Bien que la frontière soit mince entre la partie <em>Scala</em> et <em>Akka</em> soit mince, les
point suivants sont généralement liés uniquement à la synthaxe <em>Scala</em>, et plus au
paradigme de programmation <em>Akka</em>.</p>
<div class="section" id="tache-15-mise-en-relation-du-scoring-pour-le-retour-a-lalgorithmactor">
<h3>Tâche 15 : Mise en relation du scoring pour le retour à l’AlgorithmActor<a class="headerlink" href="#tache-15-mise-en-relation-du-scoring-pour-le-retour-a-lalgorithmactor" title="Lien permanent vers ce titre">¶</a></h3>
<p>Ce point n’est pas encore implémenté, et, comme dit lors de la phase de conception,
le format de retour du container pour les prédicats n’est pas encore fixé.</p>
<p>Il n’y a pas de difficulté majeure en vue, étant donné que l’on a le contrôle sur
le format de sortie du container, ainsi que sur le traitement avant le retour des prédicats
sous format <em>PFA</em> au <cite>AlgorithmActor</cite>. La définition sera effectuée quand la partie
<em>Akka</em> sera implémentée et fonctionnelle.</p>
</div>
<div class="section" id="tache-16-configuration-des-definitions-de-containers-dalgorithmes">
<h3>Tâche 16 : Configuration des définitions de containers d’algorithmes<a class="headerlink" href="#tache-16-configuration-des-definitions-de-containers-dalgorithmes" title="Lien permanent vers ce titre">¶</a></h3>
<p>Woken envoie des demandes d’exécution d’algorithmes à Chronos sous format <cite>JSON</cite>.
Il doit stipuler l’image et la version pour chaque algorithme disponible à l’utilisateur.
Le fichier de configuration est propre à l’environnement, soit <cite>dev-debug</cite> ou <cite>dev-test</cite>.</p>
<p>Ces fichiers de configurations sont disponible dans l’arborescence au chemin <cite>/dev-*/woken/cofig/application.conf</cite>.</p>
<div class="highlight-conf"><div class="highlight"><pre><span></span>{
  functions {
    statisticsSummary = {
      image = &quot;hbpmip/r-summary-stats:2afe249&quot;
      predictive = false
    }
    anova = {
      image = &quot;hbpmip/r-linear-regression:2afe249&quot;
      predictive = false
    }
    linearRegression = {
      image = &quot;hbpmip/r-linear-regression:2afe249&quot;
      predictive = false
    }
    knn = {
      image = &quot;hbpmip/java-rapidminer-knn:58e280f&quot;
      predictive = true
    }
    naiveBayes = {
      image = &quot;hbpmip/java-rapidminer-naivebayes:58e280f&quot;
      predictive = true
    }
    tpot = {
      image = &quot;axelroy/python-mip-tpot:0.0.1&quot;
      predictive = true
    }
  }
}
</pre></div>
</div>
<p>Cette exemple montre que l’on définit le nom l’image et la version à utiliser pour
résoudre un algorithme. Si l’image n’est pas présente localement, elle sera reprise
depuis le <em>Docker-Hub</em>. Le flag prédictive indique si la voie à utiliser peut être
<code class="code docutils literal"><span class="pre">mining/experiment</span></code>.</p>
<p>A l’avenir, il est probable qu’un tag «&nbsp;interactive&nbsp;» définisse si on peut utiliser
le nouveau flux de travail interactif implémenté dans ce travail.</p>
<p>Pour information, il est prévu que ce flux soit utilisé afin de mettre à disposition
les algorithmes de <em>scikit-learn</em> via ce nouveau flux, car les prédicats pourront
s’effectuer via une simple représentation du texte du pipeline.</p>
</div>
<div class="section" id="tache-17-mise-en-place-de-la-nouvelle-structure-de-case-classes-pour-les-volumes">
<h3>Tâche 17 : Mise en place de la nouvelle structure de case classes pour les volumes<a class="headerlink" href="#tache-17-mise-en-place-de-la-nouvelle-structure-de-case-classes-pour-les-volumes" title="Lien permanent vers ce titre">¶</a></h3>
<p>La représentation d’un <code class="code docutils literal"><span class="pre">Job</span></code> donné à Chronos est effectué via des case-classes
<em>Scala</em> directement dans <em>Woken</em>. Cette définition n’intégrait pas les notions de
<cite>volumes</cite> et de <cite>commandes</cite> dans le flux actuel. Les volumes n’étaient pas utilisés,
et la commande était systématiquement définie comme <code class="code docutils literal"><span class="pre">compute</span></code>.</p>
<p>Il a été nécessaire d’ajouter des définitions supplémentaires pour les <cite>volumes</cite> <a class="reference internal" href="#wokenvolume" id="id49">[32]</a>
et de laisser la possibilité de définir une autre commande que <code class="code docutils literal"><span class="pre">compute</span></code> <a class="reference internal" href="#wokencommands" id="id50">[33]</a>
pour l’entrypoint.</p>
<p>La sérialisation est gérée par Spray <a class="reference internal" href="#spray" id="id51">[36]</a>. Des tests unitaires ont été implémentés
pour vérifier le format. Ils sont disponibles au chemin <code class="code docutils literal"><span class="pre">/src/test/scala/JSONFormat/JSONFormattingTests.scala</span></code>.</p>
</div>
<div class="section" id="tache-18-generation-automatique-des-repertoires-pour-la-liaison-des-volumes">
<h3>Tâche 18 : Génération automatique des répertoires pour la liaison des volumes<a class="headerlink" href="#tache-18-generation-automatique-des-repertoires-pour-la-liaison-des-volumes" title="Lien permanent vers ce titre">¶</a></h3>
<p>A l’instant de la rédaction de ce rapport, le chemin pour la liaison de <em>volume</em> est
hard-codé. Ceci n’est pas viable quand le flux d’acteur est complet.</p>
<p>La problématique dans le cadre de l’architecture distribuée sur laquelle fonctionne
Mesos est qu’il n’y a pas de système de fichier centralisé, ce qui implique que
deux appels successifs via un acteur Woken doit s’effectuer sur la même machine physique
afin que le résultat de l’entrainement soit récupérable pour les prédicats. Ce problème
peut être résolu en forcant tous les containers TPOT instanciés à être placés sur le
même hôte. Les recherches pour ce faire n’ont pas encore été effectuées.</p>
<p>En imaginant que le point ci-dessus est le cas, il existe encore un problème de concurrence.
Dans un cadre de production, le chemin d’optimisation sera utilisé par plusieurs acteurs
en parralèlle, il est indispensable que chacun ait son propre répertoire de travail.</p>
<p>Chaque acteur s’occupe de l’instancier avec un nom lié au UUID, identifiant unique utilisé
dans la génération de nom pour les tâches <em>Chronos</em>. Il est possible de demander un
identifiant unique, de vérifier si le répertoire existe sur le disque.</p>
<p>Si c’est le cas, on demande un nouveau UUID. Sinon, on le crée, et on travaille dans
celui-ci le temps du flux de l”<em>InteractiveActor</em>.</p>
<p>Avec cette implémentation, chaque acteur peut travailler de manière autonome,
sans devoir tenir compte d’un dictionnaire de répertoires global pour les acteurs.</p>
</div>
</div>
<div class="section" id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Lien permanent vers ce titre">¶</a></h2>
<div class="section" id="tache-19-sortie-de-woken-du-container-pour-permettre-un-debuggage-en-natif">
<h3>Tâche 19 : Sortie de Woken du container pour permettre un débuggage en natif<a class="headerlink" href="#tache-19-sortie-de-woken-du-container-pour-permettre-un-debuggage-en-natif" title="Lien permanent vers ce titre">¶</a></h3>
<p>C’est la première fois qu’un externe aux ressources du CHUV travaille sur <em>Woken</em>.
Il a été nécessaire d’adapter et de substituer les dépendances qui étaient <em>hard-codées</em>,
comme par exemple la base de données des patients qui a été substituée par une base
de données fictive.</p>
<p>Le fruit de ce travail est un nouveau repertoire <code class="code docutils literal"><span class="pre">dev-debug</span></code>, qui contient
un <code class="code docutils literal"><span class="pre">docker-compose</span></code> permettant de mettre en place une architecture qui permet
de peupler les bases de données, mettre en place l’architecture distribuée (<em>Mesos, ZooKeeper</em>)
ainsi que les outils pour l’utiliser (<em>Chronos</em>).</p>
<p>L’environnement de test se démarre via le script <code class="code docutils literal"><span class="pre">run.sh</span></code>. Il arrive que <code class="code docutils literal"><span class="pre">Mesos-slave</span></code>
ne se coordonne pas correctement avec <code class="code docutils literal"><span class="pre">Mesos-master</span></code>, et qu’il ne donne pas de code d’erreur.</p>
<p>Si c’est le cas, cela ce manifeste par des containers qui restent en état «&nbsp;queued&nbsp;»
dans le GUI de [Chronos]. Pour le relancer : <code class="code docutils literal"><span class="pre">docker-compose</span> <span class="pre">up</span> <span class="pre">mesos-slave</span></code>.</p>
<p>Une fois la stack lancée, il est possible d’utiliser <em>IntelliJ</em> en natif, et de débugger via celui-ci.</p>
<p>Il a fallu comprendre l’architecture pour effectuer le passage en natif de <em>Woken</em>.</p>
</div>
<div class="section" id="tache-20-adaptation-du-docker-compose-pour-gerer-les-bases-de-donnees-via-les-migrations">
<h3>Tâche 20 : Adaptation du docker-compose pour gérer les bases de données via les migrations<a class="headerlink" href="#tache-20-adaptation-du-docker-compose-pour-gerer-les-bases-de-donnees-via-les-migrations" title="Lien permanent vers ce titre">¶</a></h3>
<p>De base, le container <em>Docker</em> de <em>PostgresSQL</em> est prévu pour charger un script de base
de données dans le volume</p>
</div>
<div class="section" id="tache-21-mise-a-jour-du-docker-compose-pour-le-validation-pool-akka">
<h3>Tâche 21 : Mise à jour du docker-compose pour le validation-pool Akka<a class="headerlink" href="#tache-21-mise-a-jour-du-docker-compose-pour-le-validation-pool-akka" title="Lien permanent vers ce titre">¶</a></h3>
</div>
</div>
<div class="section" id="compte-rendu-graphique-de-l-avancement-du-projet">
<h2>Compte rendu graphique de l’avancement du projet<a class="headerlink" href="#compte-rendu-graphique-de-l-avancement-du-projet" title="Lien permanent vers ce titre">¶</a></h2>
<div class="figure align-center" id="id74">
<span id="progressrepresentation"></span><a class="reference internal image-reference" href="_images/implementationRepresentationProgress.png"><img alt="Représentation graphique des tâches effectuées." src="_images/implementationRepresentationProgress.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-text">Représentation graphique de l’avancement des tâches. Les tâches vertes sont
totalement implémentées et testées, les tâches oranges sont en cours de réalisation
et les tâches rouges ne sont pas commencées.</span></p>
</div>
</div>
</div>
<div class="section" id="validation-experience">
<h1>Validation (Expérience)<a class="headerlink" href="#validation-experience" title="Lien permanent vers ce titre">¶</a></h1>
<dl class="docutils">
<dt>6.1 Présentation de l’expérience</dt>
<dd>6.1.1 pourquoi
6.1.2 comment
6.1.3 les conditions de tests</dd>
</dl>
<p>6.2 Résultats de l’expérience
6.3 Discussion des résultats</p>
</div>
<div class="section" id="conclusion">
<h1>Conclusion<a class="headerlink" href="#conclusion" title="Lien permanent vers ce titre">¶</a></h1>
<div class="section" id="etat-des-lieux-au-moment-du-rendu">
<h2>Etat des lieux au moment du rendu<a class="headerlink" href="#etat-des-lieux-au-moment-du-rendu" title="Lien permanent vers ce titre">¶</a></h2>
<ul class="simple">
<li>Atteintes des objectifs<ul>
<li>Le contexte du mandant a-t-il été compris?</li>
<li>L’API se superposant à Marathon fonctionne-t-elle?</li>
<li>Un format de métadonnées a-t-il été spécifié? Existe-t-il un moyen
de vérifier que telle ou telle image Docker respecte ce format?</li>
<li>Un démonstrateur a-t-il été développé?</li>
</ul>
</li>
<li>Améliorations possibles</li>
</ul>
</div>
<div class="section" id="perspectives-et-ameliorations">
<h2>Perspectives et améliorations<a class="headerlink" href="#perspectives-et-ameliorations" title="Lien permanent vers ce titre">¶</a></h2>
</div>
<div class="section" id="bilan-personnel-presenter-ce-qui-apporte-quelque-chose">
<h2>Bilan personnel (Présenter ce qui apporte quelque chose)<a class="headerlink" href="#bilan-personnel-presenter-ce-qui-apporte-quelque-chose" title="Lien permanent vers ce titre">¶</a></h2>
</div>
</div>
<div class="section" id="remerciements">
<h1>Remerciements<a class="headerlink" href="#remerciements" title="Lien permanent vers ce titre">¶</a></h1>
</div>
<div class="section" id="annexes-references-et-table-des-illustrations">
<h1>Annexes, références et Table des illustrations.<a class="headerlink" href="#annexes-references-et-table-des-illustrations" title="Lien permanent vers ce titre">¶</a></h1>
<p>TODO:Annexes :
- CdC
- Journal de travail
- TPOT papers
- FULL Rest API for TPOT</p>
<p id="bibtex-bibliography-index-0"><table class="docutils citation" frame="void" id="metronome" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id29">[1]</a></td><td>DCOS/Metronome&nbsp;- Apache. Apache mesos framework for scheduled jobs - github page. <span><a class="reference external" href="#"></a></span>https://github.com/dcos/metronome, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="autoweka" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id12">[2]</a></td><td>auto-WEKA. Automatic model selection and hyperparameter optimization in weka. <span><a class="reference external" href="#"></a></span>http://www.cs.ubc.ca/labs/beta/Projects/autoweka/, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wokenaxel" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id25">[3]</a></td><td>axelroy. Woken - an orchestration platform for docker containers running data mining algorithms - forked by axelroy on github. <span><a class="reference external" href="#"></a></span>https://github.com/axelroy/woken/tree/AutoML, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="googleautoml" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id8">[4]</a></td><td>Google developers. Google i/o keynote (google i/o “17). <span><a class="reference external" href="#"></a></span>https://www.youtube.com/watch?v=Y2VF8tmLFHw, May 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="datagridsearchdoc" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[5]</a></td><td>Scikit-Learn’s Documentation. Tuning the hyper-parameters of an estimator. <span><a class="reference external" href="#"></a></span>http://scikit-learn.org/stable/modules/grid_search.html, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="mesosdoc" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id17">[6]</a></td><td>Apache&nbsp;Software Foundation. Apache mesos. <span><a class="reference external" href="#"></a></span>http://mesos.apache.org, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="marathonapidoc" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id18">[7]</a></td><td>Apache&nbsp;Software Foundation. Marathon rest api. <span><a class="reference external" href="#"></a></span>https://mesosphere.github.io/marathon/docs/rest-api.html, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="theorymlms" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[8]</a></td><td>Philippe Beraud -&nbsp;Microsoft France. Un peu de théorie pour l’apprentissage non-supervisé). <span><a class="reference external" href="#"></a></span>https://blogs.msdn.microsoft.com/big_data_france/2014/06/06/un-peu-de-thorie-pour-lapprentissage-non-supervis/, June 2014.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="groovytron" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id16">[9]</a></td><td>Julien M’Poy&nbsp;/ Groovytron. Maracker’s repository : api aiming to make human brain project’s medical informatics platform’s developped apps deployment on mesos marathon easier. <span><a class="reference external" href="#"></a></span>https://github.com/groovytron/maracker, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="pfa" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id26">[10]</a></td><td>DMG - Data&nbsp;Mining Group. Pfa - portable format for analytics). <span><a class="reference external" href="#"></a></span>http://dmg.org/pfa/index.html, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dockerimages" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[11]</td><td><em>(<a class="fn-backref" href="#id39">1</a>, <a class="fn-backref" href="#id41">2</a>)</em> HBPMedical. Docker’s python implementation for the hbp-mip plateform’s algorithm implementation - github. <span><a class="reference external" href="#"></a></span>https://github.com/axelroy/python-base-docker-images/tree/python-mip-interactive, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="hhusain" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id10">[12]</a></td><td>Hamel Husain. Automated machine learning — a paradigm shift that accelerates data scientist productivity &#64; airbnb. <span><a class="reference external" href="#"></a></span>https://medium.com/airbnb-engineering/automated-machine-learning-a-paradigm-shift-that-accelerates-data-scientist-productivity-airbnb-f1f8a10d61f8, July 2016.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="hyperopt" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id13">[13]</a></td><td>hyperopt. Hyperopt - distributed asynchronous hyperparameter optimization in python. <span><a class="reference external" href="#"></a></span>http://hyperopt.github.io/hyperopt, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="createbaseimagedocker" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id19">[14]</a></td><td>Docker Inc. Create a base image - docker documentation. <span><a class="reference external" href="#"></a></span>https://docs.docker.com/engine/userguide/eng-image/baseimages/#create-a-full-image-using-tar, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dockerfilereference" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id20">[15]</a></td><td>Docker Inc. Dockerfile reference - docker documentation. <span><a class="reference external" href="#"></a></span>https://docs.docker.com/engine/reference/builder/, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dockervolumes" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id30">[16]</a></td><td>Docker Inc. Manage data in containers - docker’s documentation. <span><a class="reference external" href="#"></a></span>https://docs.docker.com/engine/tutorials/dockervolumes/, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="zombiesdocker" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id43">[17]</a></td><td>Hongli Lai. Docker and the pid 1 zombie reaping problem. <span><a class="reference external" href="#"></a></span>https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/, January 2015.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="id53" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id22">[18]</a></td><td>Switzerland Lausanne (EPFL)&nbsp;Lausanne. The scala programming language. <span><a class="reference external" href="#"></a></span>https://www.scala-lang.org/, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="id54" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id23">[19]</a></td><td>AKKA Lightbend&nbsp;Inc. Akka official website. <span><a class="reference external" href="#"></a></span>http://akka.io, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="stateautoml" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id9">[20]</a></td><td>Matthew Mayo. The current state of automated machine learning). <span><a class="reference external" href="#"></a></span>http://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html, Jan 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="olson2016evaluation" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[21]</a></td><td>Randal&nbsp;S Olson, Nathan Bartley, Ryan&nbsp;J Urbanowicz, and Jason&nbsp;H Moore. Evaluation of a tree-based pipeline optimization tool for automating data science. In <em>Proceedings of the 2016 on Genetic and Evolutionary Computation Conference</em>, 485–492. ACM, 2016.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="olson2016tpot" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[22]</a></td><td>Randal&nbsp;S Olson and Jason&nbsp;H Moore. Tpot: a tree-based pipeline optimization tool for automating machine learning. In <em>Workshop on Automatic Machine Learning</em>, 66–74. 2016.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="olson2016evobio" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[23]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id5">2</a>, <a class="fn-backref" href="#id11">3</a>, <a class="fn-backref" href="#id14">4</a>)</em> Randal&nbsp;S. Olson, Ryan&nbsp;J. Urbanowicz, Peter&nbsp;C. Andrews, Nicole&nbsp;A. Lavender, La&nbsp;Creis Kidd, and Jason&nbsp;H. Moore. <em>Applications of Evolutionary Computation: 19th European Conference, EvoApplications 2016, Porto, Portugal, March 30 – April 1, 2016, Proceedings, Part I</em>. Springer International Publishing, 2016. ISBN 978-3-319-31204-0. URL: <a class="reference external" href="http://dx.doi.org/10.1007/978-3-319-31204-0_9">http://dx.doi.org/10.1007/978-3-319-31204-0_9</a>, <a class="reference external" href="https://doi.org/10.1007/978-3-319-31204-0_9">doi:10.1007/978-3-319-31204-0_9</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tpotissuerefactor" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id37">[24]</a></td><td>Randy Olson. Refactor: _fitted_pipeline, _pareto_front_fitted_pipelines, and _evaluated_individuals - github issue. <span><a class="reference external" href="#"></a></span>https://github.com/rhiever/tpot/issues/474, May 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tini" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id45">[25]</a></td><td>Thomas Orozco. A tiny but valid `init` for containers - github. <span><a class="reference external" href="#"></a></span>https://github.com/krallin/tini, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="scikit-learn" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[26]</td><td><em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id15">2</a>)</em> F.&nbsp;Pedregosa, G.&nbsp;Varoquaux, A.&nbsp;Gramfort, V.&nbsp;Michel, B.&nbsp;Thirion, O.&nbsp;Grisel, M.&nbsp;Blondel, P.&nbsp;Prettenhofer, R.&nbsp;Weiss, V.&nbsp;Dubourg, J.&nbsp;Vanderplas, A.&nbsp;Passos, D.&nbsp;Cournapeau, M.&nbsp;Brucher, M.&nbsp;Perrot, and E.&nbsp;Duchesnay. Scikit-learn: machine learning in Python. <em>Journal of Machine Learning Research</em>, 12:2825–2830, 2011.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dockerhubtpot" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id42">[27]</a></td><td>Axel Roy. Tpot’s implementation’s container for the integration in hbp woken’s project - github. <span><a class="reference external" href="#"></a></span>https://hub.docker.com/r/axelroy/python-mip-tpot/, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tpotcode" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id35">[28]</a></td><td>Axel Roy. Tpot’s python script implementation for the docker container - github. <span><a class="reference external" href="#"></a></span>https://github.com/axelroy/python-base-docker-images/blob/python-mip-interactive/python-mip-interactive/scripts/main.py, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tpottests" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id27">[29]</a></td><td>Axel Roy. Tests with the tpot library github page. <span><a class="reference external" href="#"></a></span>https://github.com/axelroy/TPOT_Tests, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tiniimplementation" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id44">[30]</a></td><td>Axel Roy. Tini’s implementation in the mip python container for activewait - github. <span><a class="reference external" href="#"></a></span>https://github.com/axelroy/python-base-docker-images/blob/python-mip-interactive/Old/python-mip-interactive-activewait/Dockerfile#L17, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tpotissue" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[31]</td><td><em>(<a class="fn-backref" href="#id28">1</a>, <a class="fn-backref" href="#id36">2</a>)</em> Axel Roy. Visualize constructed features and get best pipeline found. <span><a class="reference external" href="#"></a></span>https://github.com/rhiever/tpot/issues/459, May 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wokenvolume" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id49">[32]</a></td><td>Axel Roy. Woken’s implementation for volumes serialization - github. <span><a class="reference external" href="#"></a></span>https://github.com/axelroy/woken/commit/6fdafc881acef18b52b95314d94c0b969433b10d, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wokencommands" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id50">[33]</a></td><td>Axel Roy. Woken’s implementation for commands serialization - github. <span><a class="reference external" href="#"></a></span>https://github.com/axelroy/woken/commit/b71a3d4cccc444dbccf0ba1837edc51d431ac5ca, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="captain" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id40">[34]</a></td><td>Harbur Cloud&nbsp;Solutions S.L. Captain - convert your git workflow to docker containers ). <span><a class="reference external" href="#"></a></span>https://github.com/harbur/captain, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="codeerrorissue" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id21">[35]</a></td><td>sallyom. Change “docker run” exit codes to distinguish docker/contained errors #14012. <span><a class="reference external" href="#"></a></span>https://github.com/moby/moby/pull/14012, December 2015.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="spray" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id51">[36]</a></td><td>SPRAY. A lightweight, clean and simple json implementation in scala - github. <span><a class="reference external" href="#"></a></span>https://github.com/spray/spray-json, July 2017.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="zeromq" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id31">[37]</a></td><td>ZeroMQ. <span><a class="reference external" href="#"></a></span>http://zeromq.org, July 2017.</td></tr>
</tbody>
</table>
</p>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="#">Table des Matières</a></h3>
  <ul>
<li><a class="reference internal" href="#">Bienvenue sur la documentation du travail de Bachelor Auto ML</a></li>
<li><a class="reference internal" href="#introduction">Introduction</a><ul>
<li><a class="reference internal" href="#contexte-du-projet">Contexte du projet</a><ul>
<li><a class="reference internal" href="#human-brain-projet">Human Brain projet</a></li>
<li><a class="reference internal" href="#presentation-de-la-plateforme-mip">Présentation de la plateforme MIP</a></li>
<li><a class="reference internal" href="#but-du-projet">But du projet</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#cahier-des-charges-lien-vers-les-annexes-je-suppose-en-sachant-qu-il-est-explique-en-detail-dans-le-document">Cahier des charges (lien vers les annexes je suppose, en sachant qu’il est expliqué en détail dans le document)</a></li>
<li><a class="reference internal" href="#etat-de-l-art">Etat de l’Art</a><ul>
<li><a class="reference internal" href="#theorie-machine-learning">Théorie Machine Learning</a><ul>
<li><a class="reference internal" href="#apprentissage-supervise">Apprentissage supervisé</a></li>
<li><a class="reference internal" href="#apprentissage-non-supervise">Apprentissage non supervisé</a></li>
<li><a class="reference internal" href="#apprentissage-semi-supervise">Apprentissage semi-supervisé</a></li>
</ul>
</li>
<li><a class="reference internal" href="#optimisation-automatique-du-pipeline-d-apprentissage">Optimisation automatique du pipeline d’apprentissage</a></li>
<li><a class="reference internal" href="#technologies">Technologies</a><ul>
<li><a class="reference internal" href="#tpot">TPOT</a></li>
<li><a class="reference internal" href="#systemes-distribues">Systèmes distribués</a></li>
<li><a class="reference internal" href="#mesos">Mesos</a></li>
<li><a class="reference internal" href="#marathon">Marathon</a></li>
<li><a class="reference internal" href="#chronos">Chronos</a></li>
<li><a class="reference internal" href="#docker">Docker</a></li>
<li><a class="reference internal" href="#scala">Scala</a></li>
<li><a class="reference internal" href="#akka">AKKA</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id24">Analyse</a><ul>
<li><a class="reference internal" href="#woken">Woken</a><ul>
<li><a class="reference internal" href="#place-de-woken-dans-l-architecture">Place de Woken dans l’architecture</a></li>
<li><a class="reference internal" href="#fonctionnement-interne-de-woken">Fonctionnement interne de Woken</a></li>
<li><a class="reference internal" href="#fonctionnement-actuel-des-containers-docker">Fonctionnement actuel des containers Docker</a></li>
<li><a class="reference internal" href="#tests-preliminaires-avec-tpot">Tests préliminaires avec TPOT</a></li>
<li><a class="reference internal" href="#le-cas-de-marathon">Le cas de Marathon</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#conception">Conception</a><ul>
<li><a class="reference internal" href="#modification-globale-du-workflow-woken">Modification globale du workflow Woken</a></li>
<li><a class="reference internal" href="#conception-pour-tpot">Conception pour TPOT</a></li>
<li><a class="reference internal" href="#systeme-de-containers-interactifs">Système de containers interactifs</a></li>
<li><a class="reference internal" href="#id32">Chronos</a></li>
<li><a class="reference internal" href="#id33">Akka</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-realisee">Implémentation réalisée</a><ul>
<li><a class="reference internal" href="#presentation-des-taches">Présentation des tâches</a></li>
<li><a class="reference internal" href="#id34">TPOT</a><ul>
<li><a class="reference internal" href="#tache-1-recuperation-du-meilleur-pipeline">Tâche 1 : Récupération du meilleur pipeline</a></li>
<li><a class="reference internal" href="#tache-2-liaison-de-la-bdd-du-chuv-mise-en-forme-du-dataset-pour-tpot-et-decoupage-du-dataset">Tâche 2 : Liaison de la BDD du CHUV, mise en forme du dataset pour TPOT et découpage du dataset</a></li>
<li><a class="reference internal" href="#tache-3-analyse-du-type-de-features">Tâche 3 : Analyse du type de features</a></li>
<li><a class="reference internal" href="#tache-4-reconstruction-du-pipeline-via-la-description-texte-cree-par-tpot">Tâche 4 : Reconstruction du pipeline via la description texte crée par TPOT</a></li>
<li><a class="reference internal" href="#tache-5-retour-des-predictions">Tâche 5 : Retour des prédictions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id38">Docker</a><ul>
<li><a class="reference internal" href="#tache-6-implementation-dun-container-stateful">Tâche 6 : Implémentation d’un container stateful</a></li>
<li><a class="reference internal" href="#tache-7-gestion-des-entrypoints">Tâche 7 : Gestion des entrypoints</a></li>
<li><a class="reference internal" href="#tache-8-variables-denvironnements">Tâche 8 : Variables d’environnements</a></li>
<li><a class="reference internal" href="#tache-9-gestion-des-codes-derreurs">Tâche 9 : Gestion des codes d’erreurs</a></li>
<li><a class="reference internal" href="#tache-10-connexion-aux-bases-de-donnees">Tâche 10 : Connexion aux bases de données</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id46">Chronos</a><ul>
<li><a class="reference internal" href="#tache-11-instanciation-du-container-personnalise-via-le-gui">Tâche 11 : Instanciation du container personnalisé via le GUI</a></li>
<li><a class="reference internal" href="#tache-12-instanciation-du-container-via-une-requete-post-avec-un-fichier-json">Tâche 12 : Instanciation du container via une requête POST avec un fichier JSON</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id47">Akka</a><ul>
<li><a class="reference internal" href="#tache-13-mise-en-relation-du-validation-pool-akka">Tâche 13 : Mise en relation du validation pool Akka</a></li>
<li><a class="reference internal" href="#tache-14-mise-en-place-du-nouveau-flux-dacteurs-dans-woken-pour-traiter-nos-container-interactif">Tâche 14 : Mise en place du nouveau flux d’acteurs dans Woken pour traiter nos container interactif</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id48">Scala</a><ul>
<li><a class="reference internal" href="#tache-15-mise-en-relation-du-scoring-pour-le-retour-a-lalgorithmactor">Tâche 15 : Mise en relation du scoring pour le retour à l’AlgorithmActor</a></li>
<li><a class="reference internal" href="#tache-16-configuration-des-definitions-de-containers-dalgorithmes">Tâche 16 : Configuration des définitions de containers d’algorithmes</a></li>
<li><a class="reference internal" href="#tache-17-mise-en-place-de-la-nouvelle-structure-de-case-classes-pour-les-volumes">Tâche 17 : Mise en place de la nouvelle structure de case classes pour les volumes</a></li>
<li><a class="reference internal" href="#tache-18-generation-automatique-des-repertoires-pour-la-liaison-des-volumes">Tâche 18 : Génération automatique des répertoires pour la liaison des volumes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#architecture">Architecture</a><ul>
<li><a class="reference internal" href="#tache-19-sortie-de-woken-du-container-pour-permettre-un-debuggage-en-natif">Tâche 19 : Sortie de Woken du container pour permettre un débuggage en natif</a></li>
<li><a class="reference internal" href="#tache-20-adaptation-du-docker-compose-pour-gerer-les-bases-de-donnees-via-les-migrations">Tâche 20 : Adaptation du docker-compose pour gérer les bases de données via les migrations</a></li>
<li><a class="reference internal" href="#tache-21-mise-a-jour-du-docker-compose-pour-le-validation-pool-akka">Tâche 21 : Mise à jour du docker-compose pour le validation-pool Akka</a></li>
</ul>
</li>
<li><a class="reference internal" href="#compte-rendu-graphique-de-l-avancement-du-projet">Compte rendu graphique de l’avancement du projet</a></li>
</ul>
</li>
<li><a class="reference internal" href="#validation-experience">Validation (Expérience)</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a><ul>
<li><a class="reference internal" href="#etat-des-lieux-au-moment-du-rendu">Etat des lieux au moment du rendu</a></li>
<li><a class="reference internal" href="#perspectives-et-ameliorations">Perspectives et améliorations</a></li>
<li><a class="reference internal" href="#bilan-personnel-presenter-ce-qui-apporte-quelque-chose">Bilan personnel (Présenter ce qui apporte quelque chose)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#remerciements">Remerciements</a></li>
<li><a class="reference internal" href="#annexes-references-et-table-des-illustrations">Annexes, références et Table des illustrations.</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>Cette page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/index.rst.txt"
            rel="nofollow">Montrer le code source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Recherche rapide</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Axel Roy.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>